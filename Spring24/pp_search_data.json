[{"url":"cheatsheets/","title":"Cheatsheets","tags":["welcome"],"text":"Cheatsheets Getting Started with Julia - live . Fastrack to Julia  cheatsheet. MATLAB-Julia-Python comparative cheatsheet  by  QuantEcon group Plots.jl cheatsheet"},{"url":".","title":"Welcome","tags":["homepage"],"text":"Topics in Distributional Macroeconomics This website hosts some of the material for the PhD-level course  Topics in Distributional Macroeconomics  at the Tinbergen Institute Amsterdam. The corresponding Github repository is  here . The first edition of the course was in Spring 2022. Nevertheless, much of the material is unfinished. Acknowledgement \nThe design of this website is based on  Computational Thinking , a live online Julia/Pluto textbook. (computationalthinking.mit.edu) Build your own course website using https://github.com/greimel/pluto-course-template"},{"url":"installation/","title":"Software installation","tags":["welcome"],"text":"First-time setup: Install Julia & Pluto Video version: Text and pictures version: Step 1: Install Julia  1.8.2 Go to  https://julialang.org/downloads  and download the current stable release, Julia  1.8.2 , using the correct version for your operating system (Linux x86, Mac, Windows, etc). Step 2: Run Julia After installing,  make sure that you can run Julia . On some systems, this means searching for the “Julia  1.8.2 ” program installed on your computer; in others, it means running the command  julia  in a terminal. Make sure that you can execute  1 + 1 : Make sure that you are able to launch Julia and calculate  1+1  before proceeding! Step 3: Install  Pluto Next we will install the  Pluto , the notebook environment that we will be using during the course. Pluto is a Julia  programming environment  designed for interactivity and quick experiments. Open the  Julia REPL . This is the command-line interface to Julia, similar to the previous screenshot. Here you type  Julia commands , and when you press ENTER, it runs, and you see the result. To install Pluto, we want to run a  package manager command . To switch from  Julia  mode to  Pkg  mode, type  ]  (closing square bracket) at the  julia>  prompt: \njulia> ]\n\n(@v 1.8 ) pkg>\n The line turns blue and the prompt changes to  pkg> , telling you that you are now in  package manager mode . This mode allows you to do operations on  packages  (also called libraries). To install Pluto, run the following (case sensitive) command to  add  (install) the package to your system by downloading it from the internet.\nYou should only need to do this  once  for each installation of Julia: \n(@v 1.8 ) pkg> add Pluto\n This might take a couple of minutes, so you can go get yourself a cup of tea! You can now close the terminal. Step 4: Use a modern browser: Mozilla Firefox or Google Chrome We need a modern browser to view Pluto notebooks with. Firefox and Chrome work best. Second time:  Running Pluto & opening a notebook Repeat the following steps whenever you want to work on a project or homework assignment. Step 1: Start Pluto Start the Julia REPL, like you did during the setup. In the REPL, type: julia> using Pluto\n\njulia> Pluto.run()\n The terminal tells us to go to  http://localhost:1234/  (or a similar URL). Let’s open Firefox or Chrome and type that into the address bar. If you’re curious about what a  Pluto notebook  looks like, have a look at the  Featured Notebooks . These notebooks are useful for learning some basics of Julia programming. If you want to hear the story behind Pluto, have a look a the  JuliaCon presentation . If nothing happens in the browser the first time, close Julia and try again. And please let us know! Step 2a: Opening a notebook from the web This is the main menu - here you can create new notebooks, or open existing ones. Our homework assignments will always be based on a  template notebook , available in this GitHub repository. To start from a template notebook on the web, you can  paste the URL into the blue box  and press ENTER. For example, homework 0 is available  here . Go to this page, and on the top right, click on the button that says “Edit or run this notebook”. From these instructions, copy the notebook link, and paste it into the box. Press ENTER, and select OK in the confirmation box. The first thing we will want to do is to save the notebook somewhere on our own computer; see below. Step 2b: Opening an existing notebook file When you launch Pluto for the second time, your recent notebooks will appear in the main menu. You can click on them to continue where you left off. If you want to run a local notebook file that you have not opened before, then you need to enter its  full path  into the blue box in the main menu. More on finding full paths in step 3. Step 3: Saving a notebook We first need a folder to save our homework in. Open your file explorer and create one. Next, we need to know the  absolute path  of that folder. Here’s how you do that in  Windows ,  MacOS  and  Ubuntu . For example, you might have: C:\\Users\\fons\\Documents\\18S191_assignments\\  on Windows /Users/fons/Documents/18S191_assignments/  on MacOS /home/fons/Documents/18S191_assignments/  on Ubuntu Now that we know the absolute path, go back to your Pluto notebook, and at the top of the page, click on  “Save notebook…” . This is where you type the  new path+filename for your notebook : Click  Choose . Step 4: Sharing a notebook After working on your notebook (your code is autosaved when you run it), you will find your notebook file in the folder we created in step 3. This the file that you can share with others, or submit as your homework assignment to Canvas. \nconst run = f => f();\nrun(async () => {\nconst versions = await (await fetch(`https://julialang-s3.julialang.org/bin/versions.json`)).json()\nconst version_names = Object.keys(versions).sort().reverse()\nconst stable = version_names.find(v => versions[v].stable)\nconsole.log({stable})\nconst pkg_stable = /\\d+\\.\\d+/.exec(stable)[0]\ndocument.querySelectorAll(\"auto-julia-version\").forEach(el => {\n    console.log(el)\n    el.innerText = el.getAttribute(\"short\") == null ? stable : pkg_stable\n})\n});"},{"url":"search/","title":"Search results","tags":[],"text":"window.init_search(); Search Results \nLoading..."},{"url":"sidebar data/","title":"sidebar data","tags":[],"text":"Dict main \"welcome\" collections \"welcome\" .pages, \"Julia basics\" collections \"julia basics\" .pages, \"Preliminaries\" collections \"preliminaries\" .pages, , about Dict authors name \"Fabian Greimel\", url \"https www.greimel.eu\" , name \"Enrico Perotti\", url \"https www.enricoperotti.eu\" , title \"Topics in Distributional Macroeconomics\", subtitle \"PhD level Elective Course\", term \"Spring 2024\", institution \"Tinbergen Institute\", institution url \"http www.tinbergen.nl\", institution logo \"tinbergen institute logo.svg\", institution logo darkmode \"tinbergen logo white.svg\" "},{"url":"syllabus/","title":"Syllabus","tags":["welcome"],"text":"Syllabus Course Links official Canvas course page Class schedule Lecture Title Date Lecturer Notebooks Reading 1A Network Basics 1 Feb  7, 2022 Cees basic Julia ,  first networks Jackson Ch. 1 & 2 1B Network Basics 2 Feb 10, 2022 Cees coauthor network ,  power law ,  exercises Jackson Ch. 3 1C Random Networks Feb 11, 2022 Cees notebook Jackson Ch. 4–6 & 11 2A Tutorial 1: Twitter Feb 14, 2022 Cees notebook 2B Learning on Networks Feb 17, 2022 Cees notebook Jackson Ch. 8 2C Disease Transmission Feb 18, 2022 Cees notebook 3A no lecture Feb 21, 2022 3B Financial networks 1 Feb 24, 2022 Fabian notebook Allen & Gale (2000) 3C Financial networks 2 Feb 25, 2022 Fabian notebook Acemoglu et al. (2015) 4A Tutorial 2: SIR Feb 28, 2022 Cees notebook 4B Social Connectedness Mar  3, 2022 Fabian notebook Bailey et al. (2018) 4C Network Games Mar  4, 2022 Fabian Jackson Ch. 9 5A Tutorial 3: Financial stability Mar  7, 2022 Fabian notebook 5B Production networks 1 Mar 10, 2022 Fabian notebook Carvalho (2014) ,  Long & Plosser (1982) 5C Production networks 2 Mar 11, 2022 Fabian notebook Carvalho (2014) ,  Acemoglu et al. (2012) 6A Econometrics Mar 14, 2022 Cees 6B Tutorial 4: SCI Mar 17, 2022 Fabian 6C Tutorial 5: Covid Crisis Mar 18, 2022 Fabian"},{"url":"julia-basics/basic-julia/","title":"Basic Julia","tags":["julia-basics"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 1 section 1 order 1 title \"Basic Julia\" layout \"layout.jlhtml\" tags \"julia basics\" description \"\" using Markdown using InteractiveUtils using PlutoUI md\"\"\" `basic julia.jl` | Version 1.2 | last updated Feb 3 2022 \"\"\" md\" A first glance at the Julia language This notebook briefly summarizes some of the basic Julia syntax that we will need for the problem sets. \" Markdown.MD Markdown.Admonition \"warning\", \"This notebook is taken from\", md\"\"\" Computational Thinking , a live online Julia Pluto textbook. computationalthinking.mit.edu https computationalthinking.mit.edu , original notebook https github.com mitmath 18S191 blob Fall20 lecture notebooks Basic%20Julia%20syntax.jl \"\"\" md\" Variables We can define a variable using ` ` assignment . Then we can use its value in other expressions \" x 3 y 2x md\"By default Julia displays the output of the last operation. You can suppress the output by adding ` ` a semicolon at the end. \" md\"We can ask what type a variable has using `typeof` \" typeof y md\" Functions\" md\"We can use a short form, one line function definition for simple functions \" f x 2 x md\"Typing the function's name gives information about the function. To call it we must use parentheses \" f f 10 md\"For longer functions we use the following syntax with the `function` keyword and `end` \" function g x, y z x y return z^2 end g 1, 2 md\" For loops\" md\"Use `for` to loop through a pre determined set of values \" let s 0 for i in 1 10 s s i end s end md\"Here, `1 10` is a range representing the numbers from 1 to 10 \" typeof 1 10 md\"Above we used a `let` block to define a new local variable `s`. But blocks of code like this are usually better inside functions, so that they can be reused. For example, we could rewrite the above as follows \" function mysum n s 0 for i in 1 n s s 1 end return s end mysum 100 md\" Conditionals `if`\" md\"We can evaluate whether a condition is true or not by simply writing the condition \" a 3 a 5 md\"We see that conditions have a Boolean `true` or `false` value. We can then use `if` to control what we do based on that value \" if a 5 \"small\" else \"big\" end md\"\"\"Note that the `if` also returns the last value that was evaluated, in this case the string `\"small\"` or `\"big\"`, Since Pluto is reactive, changing the definition of `a` above will automatically cause this to be reevaluated \"\"\" md\" Arrays\" md\" 1D arrays `Vector`s \" md\"We can make a `Vector` 1 dimensional, or 1D array using square brackets \" v 1, 2, 3 typeof v md\"The `1` in the type shows that this is a 1D array. We access elements also using square brackets \" v 2 v 2 10 md\"Note that Pluto does not automatically update cells when you modify elements of an array, but the value does change.\" md\"A nice way to create `Vector`s following a certain pattern is to use an array comprehension \" v2 i^2 for i in 1 10 md\" 2D arrays matrices \" md\"We can make small matrices 2D arrays with square brackets too \" M 1 2 3 4 typeof M md\"The `2` in the type confirms that this is a 2D array.\" md\"This won't work for larger matrices, though. For that we can use e.g.\" zeros 5, 5 md\"Note that `zeros` gives `Float64`s by default. We can also specify a type for the elements \" zeros Int, 4, 5 md\"We can then fill in the values we want by manipulating the elements, e.g. with a `for` loop.\" md\"A nice alternative syntax to create matrices following a certain pattern is an array comprehension with a double `for` loop \" i j for i in 1 5, j in 1 6 md\"\"\" Appendix \"\"\" TableOfContents "},{"url":"julia-basics/more-julia/","title":"More Julia","tags":["julia-basics"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 1 section 2 order 1 title \"More Julia\" layout \"layout.jlhtml\" tags \"julia basics\" description \"\" using Markdown using InteractiveUtils using DataFrames using DataFrameMacros using Chain chain using PlutoUI md\"\"\" `more julia.jl` | Version 1.1 | last updated May 10 2022 | created by Daniel Schmidt https github.com danieljschmidt \"\"\" md\"\"\" More Julia \"\"\" md\"\"\" The purpose of this notebook is to make you familiar with Julia syntax that is frequently used in the course material. It also points out the peculiarities of Pluto notebooks. \"\"\" md\"\"\" Named tuples and keyword arguments Named tuples Like many other programming languages, Julia allows you to create tuples. The elements of tuples can be accessed by using the corresponding index \"\"\" standard tuple 1, 2 standard tuple 1 md\"\"\" Julia also has named tuples. Just like standard tuples, named tuples allow you to access an element using its index, but alternatively you can also access an element by its name. \"\"\" named tuple a 1, b 2 named tuple.a md\"\"\" This is convenient because it means that you do not need to remember if some parameter is the first element in a tuple or the second one. Below you can see an alternative way of creating named tuples that is frequently used in the course material \"\"\" let a 1 named tuple2 a, b 2 a is equivalent to a a end md\"\"\" Keyword arguments A similar syntax with a semicolon is used for keyword arguments that are identified by name and not by their position as normal function arguments \"\"\" function some function a, b 1 return a b end some function a 3, b 5 let a 3 some function a, b 5 a is equivalent to a a end md\"\"\" Vectorization with dot syntax You can apply a function to all elements of a vector by using the dot syntax \"\"\" 1,2,3 .^ 2 log. 1,2,3 md\"\"\" Note how Julia usually does things in a way that's mathematically consistent. Look at the following code. \"\"\" A ones 3, 3 exp A exp. A A^2 A .^ 2 md\"\"\" What would Python, R or Matlab do? \"\"\" md\"\"\" The pipe operator The pipe operator | makes it possible to write down nested function calls in a more readable way. For example, the two expressions below do the same thing \"\"\" round log named tuple.b named tuple.b | log | round md\"\"\" In case you use R The | operator in Julia is similar to the % % operator in R. \"\"\" md\"\"\" Unicode characters You can use Greek letters and other Unicode characters in your Julia code. For example, type \"\\alpha\" in the cell below without the quotation marks and press Tab on your keyboard. This should create an \\alpha symbol. \"\"\" md\"\"\" See the Julia documention https docs.julialang.org en v1 manual unicode input for a list of supported Unicode characters. For Greek letters, the abbreviations are the same as in LaTeX. \"\"\" md\"\"\" The \\in symbol An elegant way of writing loops is to use the \\in symbol instead of writing \"in\". The \\in symbol can be created by typing \"\\in\" and pressing Tab. \"\"\" i^2 for i ∈ 1 5 md\"\"\" Working with data Here are a few simple examples of working with DataFrames in Julia. If you are familiar with pandas, dplyr or Stata, have a look at this cheatsheet https dataframes.juliadata.org stable man comparisons . Also, have a look at the documentation of DataFrameMacros.jl https jkrumbiegel.github.io DataFrameMacros.jl stable which makes working with DataFrames much more convenient. \"\"\" md\"\"\" Creating a `DataFrame` \"\"\" df1 DataFrame x 1 10 md\"\"\" Transforming mutating a column \"\"\" transform df1, x ByRow x sqrt x transform df1, sqrt x uses transform from DataFrameMacros.jl md\"\"\" The ``` chain``` macro \"\"\" md\"\"\" The ``` chain``` macro works similar to the pipe operator. In the code for this course, the ``` chain``` macro is often applied to data frames together with macros from the ```DataFrameMacros``` package. \"\"\" df2 DataFrame A 1,2,2,1 , B randn 4 md\"\"\" Consider the data frame above. Let's say you would like to add up the values in the B column separately for each value of A take the absolute value of the resulting sums of B values. Using the ``` chain``` macro, we can perform this task with relatively concise code \"\"\" chain df2 begin groupby A combine sum B , automatically named C sum B specify name transform abs C end md\"\"\" Without the ``` chain``` macro, the code would look like this \"\"\" begin df groups groupby df2, A df sum combine df groups, sum B , C sum B transform df sum, abs C end md\"\"\" Pluto notebooks General advice Press F1 to see shortcuts for Pluto notebooks. Ctrl Click on an underlined variable or function to jump to its definition. Use the Live docs in the bottom right corner to get more information about any Julia function or object. Check the Github wiki https github.com fonsp Pluto.jl wiki for more information on Pluto notebooks. Automated updating of cells When changing a function or variable, Pluto automatically updates all affected cells. For example, change the value of d to some other number and see how the following cell updates automatically \"\"\" d 5 d 10 md\"\"\" This is different from jupyter notebooks in which you have to update related cells manually. The automated updating the advantage that you do not have to keep in mind the order in which to evaluate cells. However, it can also be annoying if some of the affected cells take a long time to run. At the time of writing, there is no way to turn off the automated updating but you can always manually disable cells with long run times by clicking on the three dots in the top right corner of a cell. \"\"\" md\"\"\" Only one expression per cell Pluto notebooks only allow one expression per cell. If you nevertheless want to place several expressions into the same cell, you have to use a begin ... end block \"\"\" begin e 10 f e 5 end md\"\"\" Cannot reuse variable names \"\"\" md\"\"\" Use `let` blocks to specify variable names locally. \"\"\" let g 3 end g md\"\"\" Deactivate cells \"\"\" ╠═╡ sleep 5 ╠═╡ md\"\"\" Imported Packages \"\"\" TableOfContents g 1 g 2 "},{"url":"preliminaries/aiyagari/","title":"Aiyagari","tags":["preliminaries"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 2 section 3 order 3 title \"Aiyagari\" layout \"layout.jlhtml\" tags \"preliminaries\" description \"\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end using PlutoUI Button, Slider, TableOfContents, NumberField using AlgebraOfGraphics, CairoMakie using AlgebraOfGraphics draw using DataFrameMacros using Chain chain using DataFrames using DataFrames stack using StatsBase weights using Statistics mean using LinearAlgebra using Roots find zero, Brent using QuantEcon md\"\"\" `aiyagari.jl` | Version 1.1 | last updated May 16, 2022 \"\"\" md\"\"\" Bewley Huggett Aiyagari \"\"\" md\"\"\" Households' problem \"\"\" md\"\"\" ```math \\begin align &\\max \\operatorname E 0\\Bigl \\sum t 0 ^\\infty \\beta^t u c t \\Bigr \\\\ &\\begin aligned \\text subject to &u c \\log c \\\\ &c t k t k t 1 1 r \\delta y t \\cdot w \\\\ &\\log y t \\sim \\text some Markov Chain \\\\ &y 0, k 1 \\text given \\end aligned \\end align ``` What needs to be specified parameter ``\\delta`` prices ``r``, ``w`` idiosynchratic productivity process initial state `` y 0, k 1 `` \"\"\" md\"\"\" Let ``s k, y `` be the state and ``a k' `` be the action. We can then write ```math c s,a \\cdots y \\cdot w k\\cdot 1 r \\delta k' ``` Let us also define the reward function ```math r s, a \\cdots u c s,a \\cdots ``` Rewrite this recursively, ```math \\begin align v s \\max a \\in A r s, a \\operatorname E v s' |s, a \\end align ``` \"\"\" md\"\"\" Setup \"\"\" md\"\"\" To find a solution to the households' problem, we will use the Quantecon toolbox. The toolbox requires us to specify an n \\times m array R that contains the value of the reward function for each state and action R ij r s i, a j an n \\times m \\times n array Q that gives the probability to end up in state s' in the next period for a given state s and action a in this period Q ijk \\text Prob s' s k|s s i, a a j a discount factor \\beta . For more information on this way of formulating Discrete State Dynamic Programming problems, please have a look at the QuantEcon lecture notes https julia.quantecon.org dynamic programming discrete dp.html on this topic. \"\"\" md\"\"\" As a first step, we represent household preferences by a named tuple that contains the discount factor \\beta and the utility function u \\cdot \"\"\" function Household σ 1.0, β 0.96, u σ 1 ? log x x^ 1 σ 1 1 σ β, u end md\"\"\" Moreover, the function below constructs the state space for a given grid of asset values ```k vals``` and a given Markov process ```z chain```. The resulting vector of possible states has length n and the vector of possible policies has length m . \"\"\" function statespace k vals range 1e 10, 20.0, length 200 , z chain states k, z for k ∈ k vals, z ∈ z chain.state values | vec states indices k i, z i for k i ∈ 1 length k vals , z i ∈ 1 length z chain.state values | vec policies k next for k next ∈ k vals | vec policies indices k next i for k next i ∈ 1 length k vals | vec states, states indices, policies, policies indices, z chain end md\"\"\" Now we can compute the array of transition probabilities Q If the chosen amount of assets coincides with the amount of assets in the state next period, the transition probability is equal to the transition probability for the productivity process \\text Prob z'|z . In all other cases, the transition probability is zero. \"\"\" function setup Q Q, states indices, policies indices, z chain for i next state, next ∈ enumerate states indices for i policy, k next i ∈ enumerate policies indices for i state, z i ∈ enumerate states indices if next.k i k next i Q i state, i policy, i next state z chain.p z i, next.z i end end end end return Q end function setup Q states indices, policies indices, z chain Q zeros length states indices , length policies indices , length states indices setup Q Q, states indices, policies indices, z chain Q end md\"\"\" Before we can compute the reward array R , we first need a function that can compute consumption for a given state and action. The function below allows for a higher interest rate r \\text borrow r \\Delta r for households with negative assets. \"\"\" function consumption z, k , k next , q, w, Δr if k next 0 && Δr 0 r 1 q 1 k next 0 Δr q 1 1 r end c w z k q k next end function reward state, policy, prices, u c consumption state, policy, prices if c 0 u c else 100 000 100 c end end function setup R R, states, policies, prices, u for k i, policy ∈ enumerate policies for s i, state ∈ enumerate states R s i, k i reward state, policy, prices, u end end return R end function setup R states, policies, prices, u R zeros length states , length policies setup R R, states, policies, prices, u end md\"\"\" Finally, we define a function that creates an instance of the ```DiscreteDP``` i.e. Discrete Dynamic Program class for given household preferences, a given state space and given prices. \"\"\" md\"\"\" Model parameters \"\"\" md\"\"\" First, let us define the interest rate, the wage, and the interest wedge for borrowers. We also define functions that turn the interest rate into the price of a bond q . \"\"\" r 0.02 q r 1 1 r prices q q r , w 1.0, Δr r 2 md\"\"\" Next, we define choose the parameters that govern household preferences. \"\"\" hh Household σ 2.0, β 0.96 md\"\"\" We also need to define the Markov chain for the productivity process \"\"\" z chain MarkovChain 0.75 0.25 0.25 0.75 , 1.25, 0.75 function setup DDP household, statespace, prices β, u household states, policies, states indices, policies indices statespace R setup R states, policies, prices, u Q setup Q states indices, policies indices, z chain DiscreteDP R, Q, β end md\"\"\" We combine this Markov chain with a grid for assets ```k vals``` to construct the state space. The smallest asset value on the grid defines the maximum amount that a household can borrow. The largest asset value on the grid needs to be large enough so that it does not distort the model solution. \"\"\" ss statespace k vals range 1., 5., length 200 , z chain md\"\"\" As the final step, we create an instance of the ```DiscreteDP``` class for the previously defined parameter values. \"\"\" ddp setup DDP hh, ss, prices md\"\"\" Solve households' problem \"\"\" md\"\"\" We solve the households' problem using the policy function iteration PFI algorithm from the QuantEcon toolbox. In the data frame below, each row corresponds to point in the state space. \\pi denotes the stationary distribution. \"\"\" function solve details0 ddp, states, policies solver PFI results QuantEcon.solve ddp, solver df DataFrame states DataFrame policies results.sigma df.state states df.policy policies results.sigma df.π stationary distributions results.mc , 1 1 df end function solve details ddp, states, policies solver PFI df solve details0 ddp, states, policies solver chain df begin transform consumption consumption state, policy, prices transform saving k next k select Not state, policy end end results solve details ddp, ss.states, ss.policies solver PFI md\"\"\" Policy functions The figure below show how much a household should consume and how much it should save given its current amount of assets and productivity state. \"\"\" let fg chain results begin stack Not k, z, π data mapping k L\"current assets k \", value \"policy\", layout variable, color z nonnumeric, visual Lines draw facet linkyaxes false, , legend position top, titleposition left end ax content fg.figure 2,1 fg end k first chain results begin subset k next k groupby z combine first k end md\"\"\" Below, we compute the lowest asset value at which we observe dissaving by the household. Households in the low productivity state dissave even when they are very close to the borrowing constraint, while households in the high productivity state only start dissaving above an asset level of round k first 1, \"k first\" , digits 3 . \"\"\" md\"\"\" Stationary distribution The figure below depicts the probability density over assets for separately for the two productivity levels. \"\"\" chain results begin data mapping k, π, color z nonnumeric visual Lines draw end md\"\"\" More on the stationary distribution In the first lecture you have learned that the Aiyagari model is a Markov chain with respect to the n \\times n transition matrix Q^ that is implicitly defined by the stochastic income process and the optimal savings rule. Note that Q^ is different from the n \\times m \\times n matrix Q which did not impose the optimal savings rule. In the cell below, we compute Q^ by combining the optimal savings rule with the Q matrix. We also check if the rows of Q^ sum to 1 \"\"\" begin res QuantEcon.solve ddp, PFI Q setup Q ss.states indices, ss.policies indices, ss.z chain Q star 1 zeros length ss.states , length ss.states for i state, state ∈ enumerate ss.states indices Q star 1 i state, Q i state,res.sigma i state , end sum Q star 1 dims 2 ' end md\"\"\" Within the QuantEcon framework, the Q^ matrix is saved as ```res.mc.p``` where ```res``` is some results object that is returned by the ```QuantEcon.solve``` function. Below, we check if the Q^ matrix computed by us is the same as the Q^ matrix computed by the ```QuantEcon project``` \"\"\" begin Q star 2 res.mc.p isapprox Q star 1, Q star 2 end md\"\"\" If the Markov chain is ergodic, we can obtain the stationary distribution by starting with an arbitray distribution \\pi 1 over the state space and applying the transition matrix to it until the distribution converges to the stationary distribution \\pi \\infty . You can do this using the buttons below Restart Initialize \\pi 1 such that all agents are in the high income state with zero assets Update \\pi i 1 ' \\pi i' \\cdot Q^ Feel free to choose another initialization. Note that Pluto automatically applies one update step after you press \"Restart\". \"\"\" md\"\"\" bind restart dens Button \"Restart\" bind update dens Button \"Update\" \"\"\" begin restart dens j 1 I need to use array here because otherwise Pluto complains that there are multiple definitions of j dist zeros size ss.states dist 1 1. df DataFrame ss.states df.π dist end begin update dens j 1 j 1 1 df.π df.π' Q star 1 ' print j 1 , \" iterations\" chain df begin data mapping k, π, color z nonnumeric visual Lines draw end end md\"\"\" Aggregate outcomes \"\"\" md\"\"\" The function below computes aggregate consumption, aggregate assets etc. Since we assume that there is a probability mass 1 of households, computing the aggregate variables means computing the average over the state space weighted by the stationary distribution of households. \"\"\" function aggregates results chain results begin stack Not π groupby variable combine aggregate sum value, weights π zip .variable, .aggregate Dict end end agg aggregates results md\"\"\" Interactive results \"\"\" md\"\"\" Risk aversion coefficient \\sigma \"\"\" bind σ slider Slider 1. 0.25 3., show value true, default 2. md\"\"\" Discount factor \\beta \"\"\" bind β slider Slider 0.95 0.005 0.97, show value true, default 0.96 begin hh slider Household σ σ slider, β β slider ddp slider setup DDP hh slider, ss, prices results slider solve details ddp slider, ss.states, ss.policies solver PFI end md\"\"\" Aggregate savings round mean results slider.k, weights results slider.π , digits 3 \"\"\" begin fg chain results slider begin stack Not k, z data mapping k \"current assets k\", value, layout variable, color z nonnumeric, visual Lines draw facet linkyaxes false, , legend position top, titleposition left end ax content fg.figure 2,2 ablines ax, 0, 1, color gray, linestyle dash, loose fg end md\"\"\" Huggett equilibrium \"\"\" md\"\"\" Setup To compute the Huggett equilibrium, we need a function that computes the amount of excess savings in the economy for a given interest rate r . \"\"\" function excess savings hh, statespace, r w, Δr ddp setup DDP hh, statespace, w, q q r , Δr Δr results solve details ddp, statespace.states, statespace.policies, solver PFI return ζ mean results.k, weights results.π end ζ r excess savings hh, ss, r, w prices.w, Δr prices.Δr md\"\"\" Finding the equilibrium In the Huggett equilribium, the equilibrium interest rate is the interest rate at which the excess savings \\zeta r are zero. To find this interest rate, we use the so called bisection algorithm. \"\"\" md\"\"\" Initial interval for interest rate As a first step, we need to find an interval so that excess savings are positive at one endpoint and negative at the other endpoint. Left endpoint r l bind left NumberField 0.00 0.01 0.04, 0.01 Right endpoint r r bind right NumberField 0.01 0.01 0.04, 0.03 \"\"\" md\"\"\" Excess savings at left endpoint ``\\zeta r l `` round excess savings hh, ss, left prices.w, prices.Δr , digits 4 right endpoint ``\\zeta r r `` round excess savings hh, ss, right prices.w, prices.Δr , digits 4 \"\"\" md\"\"\" If you have found such an interval, you can be sure that the excess savings function \\zeta r crosses zero at least once in this interval. This means that we can start the bisection algorithm now. Bisection algorithm One step of the bisection algorithm works as follows compute the midpoint r m 1 2 r l r d if the sign of \\zeta r m is different from the sign of \\zeta r l use the midpoint r m as the right endpoint of the new interval and leave the left endpoint unchanged if the sign of \\zeta r m is different from the sign of \\zeta r r use the midpoint r m as the left endpoint of the new interval and leave the right endpoint unchanged bind start Button \"Restart bisection\" bind go Button \"Bisect the interval\" \"\"\" begin start left vec left right vec right ζ left vec ζ left ζ right vec ζ right if ζ left vec end ζ right vec end 0. throw DomainError left, right , \"Function has the same sign at the left endpoint and at the right endpoint\" end end begin go mid left vec end right vec end 2 ζ mid ζ mid if ζ left vec end ζ mid 0. push left vec, left vec end push ζ left vec, ζ left vec end push right vec, mid push ζ right vec, ζ mid elseif ζ right vec end ζ mid 0. push left vec, mid push ζ left vec, ζ mid push right vec, right vec end push ζ right vec, ζ right vec end else throw DomainError left, right , \"Function has the same sign at the left endpoint and at the right endpoint\" end info left vec end , right vec end f Figure ax1 Axis f 1, 1 , xlabel \"interest rate r\", ylabel \"excess savings ζ\" scatter ax1, left vec, ζ left vec scatter ax1, right vec, ζ right vec vspan ax1, left vec end , right vec end , ymin 1., y max 1., color grey, 0.2 r vec vcat left vec, reverse right vec ζ vec vcat ζ left vec, reverse ζ right vec lines ax1, r vec, ζ vec, color \"black\" xlabel ax1, \"excess savings ζ\" ylabel ax1, \"interest rate r\" current figure end md\"\"\" Aiyagari equilibrium \"\"\" md\"\"\" Setup \"\"\" md\"\"\" The production function is F K, N A K^\\alpha N^ 1 \\alpha where K is the capital stock and N is labor. \"\"\" function production f, K return f.A K ^ f.α f.N ^ 1 f.α end md\"\"\" The function below creates a named tuple with all parameters that describe the technology of the firm. \"\"\" function Firm A 1, N 1, α 0.33, δ 0.05 A, N, α, δ end md\"\"\" From the first order conditions we can derive three functions that will be useful later on the capital demand function and its inverse ```K to r``` a function that computes the wage that is associated with the given interest rate \"\"\" function capital demand f, r K f.α f.A r f.δ ^ 1 1 f.α f.N return K end function K to r f, K Compute the interest rate that is associated with the given demand for capital return f.A f.α f.N K ^ 1 f.α f.δ end function r to w f, r Compute the wage that is associated with the given interest rate return f.A 1 f.α f.A f.α r f.δ ^ f.α 1 f.α end md\"\"\" Model parameters \"\"\" firm Firm md\"\"\" For the household problem, we choose other model parameters than in the Huggett model. Moreover, we use less grid points for assets to make sure that the calibration of \\beta does not take too much time. \"\"\" hh2 Household β 0.96, u log ss2 statespace k vals range 1e 10, 20.0, length 100 , z chain MarkovChain 0.9 0.1 0.1 0.9 , 0.1 1.0 md\"\"\" Finding the equilibrium \"\"\" md\"\"\" First, we have a look at the capital demand and supply curves \"\"\" function capital supply hh, f, statespace, r w r to w f, r ddp setup DDP hh, statespace, w, q q r , Δr 0.0 results solve details ddp, statespace.states, statespace.policies, solver PFI return K mean results.k, weights results.π end begin r vals supply range 0.001, 0.04, length 20 k vals capital supply. Ref hh2 , Ref firm , Ref ss2 , r vals supply r vals demand K to r. Ref firm , k vals end let fig Figure ax fig 1, 1 Axis fig, xlabel \"capital\", ylabel \"interest rate\" lines k vals, r vals demand, label \"demand\" lines k vals, r vals supply, label \"supply\" axislegend fig end function excess demand hh, f, statespace, r supply capital supply hh, f, statespace, r demand capital demand f, r return demand supply end begin initial bracket 0.005, 0.055 r eq find zero r excess demand hh2, firm, ss2, r , initial bracket, Brent k eq capital demand firm, r eq r eq, k eq end md\"\"\" To determine the exact equilibrium interest rate, we apply a root finding algorithm to a function that computes excess demand for capital for a given interest rate. We could of course use the bisection algorithm that we have used to compute the Huggett equilibrium above. But to make sure that the code is fast enough, we take the Brent algorithm https en.wikipedia.org wiki Brent%27s method which is implemented in the ```Roots.jl``` package. Since the household's decision problem needs to be solved for a different value of the interest rate at each step of the algorithm, finding the equilibrium can be time consuming, especially in more complicated models. The resulting equilibrium interest rate is round r eq, digits 4 and the associated capital stock is round k eq, digits 3 . \"\"\" wto target 3.63 md\" Calibrating the discount factor \\beta Now, let's choose the discount factor \\beta such that the wealth to output ratio K F K,N matches the US value of round wto target, digits 3 Auclert and Rognlie, 'Inequality and Aggregate Demand', Appendix B . We can achieve this by minimizing the objective function O \\beta \\left \\frac K \\beta F K \\beta ,N 3.63\\right ^2 where K \\beta denotes the equilibrium capital stock in the Aiyagari model that is associated with a given discount factor \\beta . \" function wealth to output ratio β, u, firm, statespace, initial bracket hh β Household β β, u u r eq find zero r excess demand hh β, firm, statespace, r , initial bracket, Brent , atol 1e 5, rtol 1e 5, xatol 1e 5, xrtol 1e 5 k eq capital demand firm, r eq return k eq production firm, k eq end wealth to output ratio 0.96, hh2.u, firm, ss2, initial bracket begin β vals 0.945 0.005 0.965 wto vals wealth to output ratio β, hh2.u, firm, ss2, initial bracket for β in β vals obj vals wto vals . wto target .^ 2 end lines β vals, obj vals, axis xlabel L\"discount factor β \", ylabel \"value of the objective function\" β cal find zero β wealth to output ratio β, hh2.u, firm, ss2, initial bracket wto target, 0.945, 0.965 , Brent , atol 1e 5, rtol 1e 5, xatol 1e 5, xrtol 1e 5 md\"\"\" Appendix \"\"\" TableOfContents md\"\"\" Acknowledgements This notebook has been dramatically improved by Daniel Schmidt https github.com danieljschmidt . \"\"\" "},{"url":"preliminaries/lifecycle/","title":"Lifecycle models","tags":["preliminaries"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 2 section 4 order 4 title \"Lifecycle models\" layout \"layout.jlhtml\" tags \"preliminaries\" description \"\" using Markdown using InteractiveUtils using QuantEcon using Chain, DataFrameMacros, DataFrames using CairoMakie using AlgebraOfGraphics draw using StatsBase using StatsBase weights using AlgebraOfGraphics using AlgebraOfGraphics density using AoGExtensions using LinearAlgebra using LightGraphs using PlutoUI TableOfContents md\"\"\" danger \"Under construction \" This notebook is not ready for public consumption. Use at your own risk. \"\"\" md\"\"\" `lifecycle.jl` | Version 0.1 | last updated Apr 13 2022 \"\"\" md\"\"\" Lifecycle models The setup should be basically identical to the one in `aiyagari.jl`, except that demographic structure is changed. We'll cover the case of finite lifetime and perpetual youth. \"\"\" md\"\"\" Setup \"\"\" function statespace a vals range 1e 10, 20.0, length 200 , z chain states a, z for a ∈ a vals, z ∈ z chain.state values | vec states indices a i, z i for a i ∈ 1 length a vals , z i ∈ 1 length z chain.state values | vec policies a next for a next ∈ a vals | vec policies indices a next i for a next i ∈ 1 length a vals | vec states, states indices, policies, policies indices, z chain end function Household σ 1.0, β 0.96, m 0.0, u σ 1 ? log x x^ 1 σ 1 1 σ β, u, m end function setup Q Q, states indices, policies indices, z chain for i next state, next ∈ enumerate states indices for i policy, a next i ∈ enumerate policies indices for i state, z i ∈ enumerate states indices if next.a i a next i Q i state, i policy, i next state z chain.p z i, next.z i end end end end return Q end function setup Q states indices, policies indices, z chain Q zeros length states indices , length policies indices , length states indices setup Q Q, states indices, policies indices, z chain Q end function consumption z, a , a next , q, w, Δr if a next 0 && Δr 0 r 1 q 1 a next 0 Δr q 1 1 r end c w z a q a next c, a next end function reward etc state, policy, prices, u c, a next consumption state, policy, prices if c 0 reward u c else reward 100 000 100 c end reward, c end function setup R etc R, etc, states, policies, prices, u for i policy, policy ∈ enumerate policies for i state, state ∈ enumerate states out reward etc state, policy, prices, u R i state, i policy out.reward etc i state, i policy out... end end return nothing end function setup R etc states, policies, prices, u proto reward etc first states , first policies , prices, u T typeof proto etc Array T undef, length states , length policies R zeros length states , length policies setup R etc R, etc, states, policies, prices, u R, etc end md\"\"\" State space \"\"\" r guess hh, scale 0.9 1 hh.β 1 hh.m scale q r 1 1 r r from q q 1 q 1 md\"\"\" Solve Households' problem \"\"\" md\"\"\" Infinite lifetime vs finite lifetime vs perpetual youth \"\"\" md\"\"\" Finite lifetime \"\"\" J 40 Create an instance of Household hh Household m 1 J r r guess hh, 0.8 prices q q r , w 1.0, Δr r 2 function simulate J ddp, J, v term, states, policies , other policies, π₀ vs, sigmas backward induction ddp, J, v term initial distribution π copy π₀ initialize DataFrame to store the results dfs DataFrame for j ∈ 1 J σ sigmas , j R σ, Q σ RQ sigma ddp, σ op DataFrame other policies i, s for i, s ∈ enumerate σ df DataFrame states DataFrame policies σ op df.j . j df.π vec π π π Q σ Q initial distribution push dfs, df end vcat dfs... end md\"\"\" Perpetual youth \"\"\" function simulate ddp, J, states, policies , other policies, π₀, solver PFI results QuantEcon.solve ddp, solver σ results.sigma R σ, Q σ RQ sigma ddp, σ op DataFrame other policies i, s for i, s ∈ enumerate σ df0 DataFrame states DataFrame policies σ op initial distribution π copy π₀ initialize DataFrame to store the results dfs DataFrame for j ∈ 1 J df copy df0 df.j . j df.π vec π π π Q σ Q initial distribution push dfs, df end vcat dfs... end md\"\"\" Evolution of assets over age \"\"\" ╠═╡ chain df big begin data mapping j, a, weights π visual Violin draw end ╠═╡ ε 0.1 z chain MarkovChain 1 ε ε ε 1 ε , 1.25, 0.75 function setup DDP household, statespace, prices β, m, u household states, policies, states indices, policies indices statespace Rewards and policies R, etc setup R etc states, policies, prices, u Transition function Q setup Q states indices, policies indices, z chain ddp DiscreteDP R, Q, β 1 m ddp, R, etc end ss statespace a vals range 2, 2.0, length 200 , z chain Use the instance to build a discrete dynamic program am ddp, etc let ddp, etc setup DDP hh, ss, prices am ddp ddp, etc end v term map ss.states do a, z a ≥ 0 ? 0 100 000 a end initial distribution let i 0 findfirst DataFrame ss.states .a . 0 π₀ map ss.states indices do a i a i i 0 ? 1.0 0.0 end π₀ sum π₀ end df big simulate J am ddp, J, v term, ss, etc, initial distribution' chain df big begin stack a, a next, c , j, π groupby j, variable combine value mean value, weights π data mapping j, value, layout variable visual ScatterLines draw facet linkyaxes false, end chain df big begin data mapping a, weights π density histogram draw end chain df big begin stack a, a next, c , j, π, z groupby j, variable data mapping j, value, weights π, color z nonnumeric, layout variable quantileband draw facet linkyaxes false, end df big2 simulate am ddp, J, ss, etc, initial distribution' chain df big2 begin stack a, a next, c , j, π groupby j, variable combine value mean value, weights π data mapping j, value, layout variable visual ScatterLines draw facet linkyaxes false, end chain df big2 begin stack a, a next, c , j, π, z groupby j, variable data mapping j, value, weights π, color z nonnumeric, layout variable quantileband draw facet linkyaxes false, end chain df big begin combine a mean a, weights π , a next mean a next, weights π , end chain df big2 begin combine a mean a, weights π , a next mean a next, weights π , end md\"\"\" Perpetual youth \"\"\" md\"\"\" constant death probability ``m`` \"\"\" m 1 45 hh perp youth Household m md\"\"\" Appendix \"\"\" md\"\"\" Stationary distribution \"\"\" begin abstract type StatDistSolver end struct Eigen StatDistSolver end struct GTH StatDistSolver end struct Iterate StatDistSolver end end function stationary distribution mc MarkovChain, solver StatDistSolver GTH kwargs... stationary distribution mc.p, solver kwargs... end function stationary distribution Q AbstractMatrix, m, solver kwargs... Q̃ 1 m Q m I stationary distribution Q̃, solver kwargs... end function stationary distribution Q AbstractMatrix, m, π₀, π m π₀ I 1 m Q π' end function stationary distribution Q AbstractMatrix, m, π₀, Iterate maxit 400, π guess π₀, rtol √eps π copy π guess for i in 1 maxit π new 1 m π Q m π₀ if isapprox π new, π rtol info \"Converged after i iterations\" return π new' end if i maxit warn \"Didn't converge after i iterations\" return π new' end π . π new end nothing end function stationary distribution Q AbstractMatrix, GTH this essentially copies the implementation of QuantEcon.jl n size Q, 1 π zeros n ids only attracting components DiGraph Q π ids . gth solve Q ids,ids π end function stationary distribution Q AbstractMatrix, Iterate rtol √eps , maxit 400 Qn copy Q for i in 1 maxit Qn new Qn Q if isapprox Qn new, Qn rtol info \"Converged after i iterations\" break end if i maxit warn \"Didn't converge after i iterations\" end Qn . Qn new end Qn 1, end function real if real x assert isreal x real x end function stationary distribution Q AbstractMatrix, Eigen values, vectors eigen Q' find unit eigenvalue i only findall values .≈ 1.0 get corresponding eigenvector π vectors , i make sure it isn't complex, normalize sum to 1 π real if real π π . π sum π end function solve details0 ddp, states, policies , other policies m, π₀, solver PFI results QuantEcon.solve ddp, solver op DataFrame other policies i, s for i, s ∈ enumerate results.sigma df hcat DataFrame states , DataFrame policies results.sigma , op, makeunique true df.value results.v df.state states df.policy policies results.sigma df.additional policies other policies results.sigma df.π stationary distribution results.mc.p, m, π₀, GTH df, results df end function solve details ddp, statespaces, etc m, π₀, solver PFI df solve details0 ddp, statespaces, etc m, π₀, solver chain df begin select Not state, policy, additional policies end end Solve using policy function iteration results df solve details am ddp, ss, etc hh.m, π₀ initial distribution', solver PFI chain results df begin combine a mean a, weights π , a next mean a next, weights π , end chain results df begin groupby a combine π sum π data mapping a, π visual Lines draw end let ddp setup DDP hh perp youth, ss, prices assert ddp.beta hh perp youth.β 1 hh perp youth.m m hh perp youth results QuantEcon.solve ddp, PFI σ results.sigma R σ, Q σ RQ sigma ddp, σ Q̃ 1 m Q σ m I mc aux MarkovChain copy Q̃ π only stationary distributions mc aux assert π ≈ stationary distribution Q̃, Eigen assert π ≈ stationary distribution Q̃, GTH assert π ≈ stationary distribution Q̃, Iterate , rtol eps ^ 3 4 assert π ≈ stationary distribution Q σ, m, Eigen assert π ≈ stationary distribution Q σ, m, π', GTH assert π ≈ stationary distribution Q σ, m, π', Iterate π guess fill 1 400, 1, 400 , rtol eps ^ 3 4 end md\"\"\" Misc \"\"\" TableOfContents "},{"url":"preliminaries/rbc-to-imrohoroglu/","title":"RBC & Imrohoroglu (1989) as Markov Chains","tags":["preliminaries"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 2 section 2 order 2 title \"RBC & Imrohoroglu 1989 as Markov Chains\" layout \"layout.jlhtml\" tags \"preliminaries\" description \"\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end using SparseArrays using QuantEcon using Chain, DataFrameMacros using CairoMakie using AlgebraOfGraphics using AlgebraOfGraphics draw using StatsBase using PlutoUI using PlutoUI Slider using DataFrames using LaTeXStrings md\"\"\" `rbc to imrohoroglu.jl` | Version 0.1 | last updated May 2 2023 \"\"\" md\"\"\" Introduction \"\"\" md\"\"\" 1. Recap Finite State Markov Chains \"\"\" ╠═╡ mc MarkovChain 0.5 0.1 0.4 0.1 0.4 0.5 0.3 0.3 0.4 , \"unemployed\", \"employed\", \"other\" ╠═╡ mc tauchen 20, 0.9, 1.0 simulate mc, 10 N length mc.state values I 1000 T 10 sim df mapreduce vcat, 1 I do i DataFrame i, t 1 T, state simulate mc, T end md\"\"\" Tracking individuals \"\"\" chain sim df begin subset i 4 subset i % 50 0 data mapping t L\"time t \", state \"state e.g. income \", color i nonnumeric visual ScatterLines mapping t naive visual VLines draw axis title \"Sample paths of selected agents\", end blue Makie.wong colors 1 md\"\"\" Tracking the whole distribution \"\"\" md\"\"\" ... in a naive way \"\"\" bind t naive Slider 1 10, default 1, show value true chain sim df begin aside begin bins sort unique .state end subset t t naive data mapping state visual Hist bins, color blue, normalization probability draw end let fig Figure chain sim df begin subset t % 10 1 aside begin xtick labels string. sort unique .t xticks collect 1 length xtick labels , xtick labels xlabel L\"time t \" ylabel \"cross sectional distribution\" axis xticks, xlabel, ylabel bins sort unique sim df.state end data mapping state, color t t naive , nonnumeric, offset t nonnumeric visual Hist bins, direction x, normalization probability, scale to 0.6 draw fig 1,1 , axis end fig end md\"\"\" ... in a more sophisticated way assuming a continuum of agents \"\"\" π₀ fill 1 N, N initial distribution bind t soph Slider 0 100, default 0, show value true barplot mc.state values, vec π₀' mc.p^ t soph , axis title latexstring \"Cross sectional distribution at \\ t t soph \\ \" let fig Figure ax Axis fig 1,1 , xlabel L\"time t \", ylabel \"cross sectional distribution\" for t ∈ 0 10 barplot ax, mc.state values, vec π₀' mc.p^t . 4, direction x, offset t, color t t soph ? Makie.wong colors 1 gray40 end fig end md\"\"\" 2. The RBC Model A Sample Path of a Markov Chain \"\"\" md\"\"\" Set up the Dynamic Program \"\"\" z chain MarkovChain 0.75 0.25 0.25 0.75 , 1.25, 0.75 r 0.02 q r 1 1 r prices q q r , w 1.0, Δr r 2 md\"\"\" Solution is a Markov Chain \"\"\" md\"\"\" 3. Bewley Huggett Aiyagari Tracking the Distribution of a Markov Chain warning \"Note\" We are not solving for the equilibrium interest rate ``r`` here. So we are in Partial Equilibrium setting of Imrohoroglu 1989 . \"\"\" md\"\"\" Specify initial distribution \"\"\" bind t soph ddp Slider 0 100, default 0, show value true md\"\"\" Appendix \"\"\" function Household σ 1.0, β 0.96, u σ 1 ? log x x^ 1 σ 1 1 σ β, u end hh Household σ 2.0, β 0.96 function statespace k vals range 1e 10, 20.0, length 200 , z chain states k, z for k ∈ k vals, z ∈ z chain.state values | vec states indices k i, z i for k i ∈ 1 length k vals , z i ∈ 1 length z chain.state values | vec policies k next for k next ∈ k vals | vec policies indices k next i for k next i ∈ 1 length k vals | vec states, states indices, policies, policies indices, z chain end ss statespace k vals range 1., 5., length 200 , z chain states DataFrame ss.states policies DataFrame ss.policies N ddp length ss.states π₀ ddp fill 1 N ddp, N ddp function setup Q Q, states indices, policies indices, z chain for i next state, next ∈ enumerate states indices for i policy, k next i ∈ enumerate policies indices for i state, z i ∈ enumerate states indices if next.k i k next i Q i state, i policy, i next state z chain.p z i, next.z i end end end end return Q end function setup Q states indices, policies indices, z chain Q zeros length states indices , length policies indices , length states indices setup Q Q, states indices, policies indices, z chain Q end function consumption z, k , k next , q, w, Δr if k next 0 && Δr 0 r 1 q 1 k next 0 Δr q 1 1 r end c w z k q k next end function reward state, policy, prices, u c consumption state, policy, prices if c 0 u c else 100 000 100 c end end function setup R R, states, policies, prices, u for k i, policy ∈ enumerate policies for s i, state ∈ enumerate states R s i, k i reward state, policy, prices, u end end return R end function setup R states, policies, prices, u R zeros length states , length policies setup R R, states, policies, prices, u end function setup DDP household, statespace, prices β, u household states, policies, states indices, policies indices statespace R setup R states, policies, prices, u Q setup Q states indices, policies indices, z chain DiscreteDP R, Q, β end ddp setup DDP hh, ss, prices results QuantEcon.solve ddp, PFI mc ddp results.mc mc ddp.p | sparse path0 simulate mc ddp, 100 let fig Figure resolution 800, 400 path DataFrame ss.states path0 lines fig 1,1 , path.k, axis title \"evolution of capital\", xlabel \"time\" lines fig 1,2 , path.z, axis title \"evolution of productivity\", xlabel \"time\" fig end barplot mc.state values, vec π₀ ddp' mc ddp.p^ t soph ddp , axis title latexstring \"Cross sectional distribution at \\ t t soph ddp \\ \" let fig Figure ax Axis fig 1,1 , xlabel L\"time t \", ylabel \"cross sectional distribution\" for t ∈ 0 10 barplot ax, mc.state values, vec π₀ ddp' mc ddp.p^t . 70, direction x, offset t, color t t soph ddp ? Makie.wong colors 1 gray40 end fig end function solve details0 ddp, states, policies solver PFI results QuantEcon.solve ddp, solver df DataFrame states DataFrame policies results.sigma df.state states df.policy policies results.sigma df.π stationary distributions results.mc , 1 1 df end function solve details ddp, states, policies solver PFI df solve details0 ddp, states, policies solver chain df begin transform consumption consumption state, policy, prices transform saving k next k select Not state, policy end end md\"\"\" Packages \"\"\" TableOfContents "}]