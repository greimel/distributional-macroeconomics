[{"url":"cheatsheets/","title":"Cheatsheets","tags":["welcome"],"text":"Cheatsheets Getting Started with Julia - live . Fastrack to Julia  cheatsheet. MATLAB-Julia-Python comparative cheatsheet  by  QuantEcon group Plots.jl cheatsheet"},{"url":".","title":"Welcome","tags":["homepage"],"text":"Topics in Distributional Macroeconomics This website hosts some of the material for the PhD-level course  Topics in Distributional Macroeconomics  at the Tinbergen Institute Amsterdam. The corresponding Github repository is  here . The first edition of the course was in Spring 2022. Nevertheless, much of the material is unfinished. Acknowledgement \nThe design of this website is based on  Computational Thinking , a live online Julia/Pluto textbook. (computationalthinking.mit.edu) Build your own course website using https://github.com/greimel/pluto-course-template"},{"url":"installation/","title":"Software installation","tags":["welcome"],"text":"First-time setup: Install Julia & Pluto Video version: Text and pictures version: Step 1: Install Julia  1.8.2 Go to  https://julialang.org/downloads  and download the current stable release, Julia  1.8.2 , using the correct version for your operating system (Linux x86, Mac, Windows, etc). Step 2: Run Julia After installing,  make sure that you can run Julia . On some systems, this means searching for the ‚ÄúJulia  1.8.2 ‚Äù program installed on your computer; in others, it means running the command  julia  in a terminal. Make sure that you can execute  1 + 1 : Make sure that you are able to launch Julia and calculate  1+1  before proceeding! Step 3: Install  Pluto Next we will install the  Pluto , the notebook environment that we will be using during the course. Pluto is a Julia  programming environment  designed for interactivity and quick experiments. Open the  Julia REPL . This is the command-line interface to Julia, similar to the previous screenshot. Here you type  Julia commands , and when you press ENTER, it runs, and you see the result. To install Pluto, we want to run a  package manager command . To switch from  Julia  mode to  Pkg  mode, type  ]  (closing square bracket) at the  julia>  prompt: \njulia> ]\n\n(@v 1.8 ) pkg>\n The line turns blue and the prompt changes to  pkg> , telling you that you are now in  package manager mode . This mode allows you to do operations on  packages  (also called libraries). To install Pluto, run the following (case sensitive) command to  add  (install) the package to your system by downloading it from the internet.\nYou should only need to do this  once  for each installation of Julia: \n(@v 1.8 ) pkg> add Pluto\n This might take a couple of minutes, so you can go get yourself a cup of tea! You can now close the terminal. Step 4: Use a modern browser: Mozilla Firefox or Google Chrome We need a modern browser to view Pluto notebooks with. Firefox and Chrome work best. Second time:  Running Pluto & opening a notebook Repeat the following steps whenever you want to work on a project or homework assignment. Step 1: Start Pluto Start the Julia REPL, like you did during the setup. In the REPL, type: julia> using Pluto\n\njulia> Pluto.run()\n The terminal tells us to go to  http://localhost:1234/  (or a similar URL). Let‚Äôs open Firefox or Chrome and type that into the address bar. If you‚Äôre curious about what a  Pluto notebook  looks like, have a look at the  Featured Notebooks . These notebooks are useful for learning some basics of Julia programming. If you want to hear the story behind Pluto, have a look a the  JuliaCon presentation . If nothing happens in the browser the first time, close Julia and try again. And please let us know! Step 2a: Opening a notebook from the web This is the main menu - here you can create new notebooks, or open existing ones. Our homework assignments will always be based on a  template notebook , available in this GitHub repository. To start from a template notebook on the web, you can  paste the URL into the blue box  and press ENTER. For example, homework 0 is available  here . Go to this page, and on the top right, click on the button that says ‚ÄúEdit or run this notebook‚Äù. From these instructions, copy the notebook link, and paste it into the box. Press ENTER, and select OK in the confirmation box. The first thing we will want to do is to save the notebook somewhere on our own computer; see below. Step 2b: Opening an existing notebook file When you launch Pluto for the second time, your recent notebooks will appear in the main menu. You can click on them to continue where you left off. If you want to run a local notebook file that you have not opened before, then you need to enter its  full path  into the blue box in the main menu. More on finding full paths in step 3. Step 3: Saving a notebook We first need a folder to save our homework in. Open your file explorer and create one. Next, we need to know the  absolute path  of that folder. Here‚Äôs how you do that in  Windows ,  MacOS  and  Ubuntu . For example, you might have: C:\\Users\\fons\\Documents\\18S191_assignments\\  on Windows /Users/fons/Documents/18S191_assignments/  on MacOS /home/fons/Documents/18S191_assignments/  on Ubuntu Now that we know the absolute path, go back to your Pluto notebook, and at the top of the page, click on  ‚ÄúSave notebook‚Ä¶‚Äù . This is where you type the  new path+filename for your notebook : Click  Choose . Step 4: Sharing a notebook After working on your notebook (your code is autosaved when you run it), you will find your notebook file in the folder we created in step 3. This the file that you can share with others, or submit as your homework assignment to Canvas. \nconst run = f => f();\nrun(async () => {\nconst versions = await (await fetch(`https://julialang-s3.julialang.org/bin/versions.json`)).json()\nconst version_names = Object.keys(versions).sort().reverse()\nconst stable = version_names.find(v => versions[v].stable)\nconsole.log({stable})\nconst pkg_stable = /\\d+\\.\\d+/.exec(stable)[0]\ndocument.querySelectorAll(\"auto-julia-version\").forEach(el => {\n    console.log(el)\n    el.innerText = el.getAttribute(\"short\") == null ? stable : pkg_stable\n})\n});"},{"url":"search/","title":"Search results","tags":[],"text":"window.init_search(); Search Results \nLoading..."},{"url":"sidebar data/","title":"sidebar data","tags":[],"text":"Dict main \"welcome\" collections \"welcome\" .pages, \"Julia basics\" collections \"julia basics\" .pages, \"Preliminaries\" collections \"preliminaries\" .pages, \"Housing\" collections \"housing\" .pages, \"Long run\" collections \"long run\" .pages, \"Continuous time\" collections \"continuous time\" .pages, , about Dict authors name \"Fabian Greimel\", url \"https www.greimel.eu\" , name \"Enrico Perotti\", url \"https www.enricoperotti.eu\" , title \"Topics in Distributional Macroeconomics\", subtitle \"PhD level Elective Course\", term \"Spring 2024\", institution \"Tinbergen Institute\", institution url \"http www.tinbergen.nl\", institution logo \"tinbergen institute logo.svg\", institution logo darkmode \"tinbergen logo white.svg\" "},{"url":"syllabus/","title":"Syllabus","tags":["welcome"],"text":"Syllabus Course Links official Canvas course page Class schedule Lecture Title Date Lecturer Notebooks Reading 1A Network Basics 1 Feb  7, 2022 Cees basic Julia ,  first networks Jackson Ch. 1 & 2 1B Network Basics 2 Feb 10, 2022 Cees coauthor network ,  power law ,  exercises Jackson Ch. 3 1C Random Networks Feb 11, 2022 Cees notebook Jackson Ch. 4‚Äì6 & 11 2A Tutorial 1: Twitter Feb 14, 2022 Cees notebook 2B Learning on Networks Feb 17, 2022 Cees notebook Jackson Ch. 8 2C Disease Transmission Feb 18, 2022 Cees notebook 3A no lecture Feb 21, 2022 3B Financial networks 1 Feb 24, 2022 Fabian notebook Allen & Gale (2000) 3C Financial networks 2 Feb 25, 2022 Fabian notebook Acemoglu et al. (2015) 4A Tutorial 2: SIR Feb 28, 2022 Cees notebook 4B Social Connectedness Mar  3, 2022 Fabian notebook Bailey et al. (2018) 4C Network Games Mar  4, 2022 Fabian Jackson Ch. 9 5A Tutorial 3: Financial stability Mar  7, 2022 Fabian notebook 5B Production networks 1 Mar 10, 2022 Fabian notebook Carvalho (2014) ,  Long & Plosser (1982) 5C Production networks 2 Mar 11, 2022 Fabian notebook Carvalho (2014) ,  Acemoglu et al. (2012) 6A Econometrics Mar 14, 2022 Cees 6B Tutorial 4: SCI Mar 17, 2022 Fabian 6C Tutorial 5: Covid Crisis Mar 18, 2022 Fabian"},{"url":"continuous-time/continuous-time-processes/","title":"Continuous time processes","tags":["continuous-time"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 6 section 1 order 1 title \"Continuous time processes\" layout \"layout.jlhtml\" tags \"continuous time\" description \"\" using Markdown using InteractiveUtils using InfinitesimalGenerators using LinearAlgebra I using Chain, DataFrameMacros using DataFrames using PlutoUI using AlgebraOfGraphics, CairoMakie md\"\"\" `continuous time processes.jl` | Version 1.1 | last updated June 9, 2022 \"\"\" md\"\"\" In this notebook we want to get some intuition for Continuous Time Markov processes Diffusion processes. \"\"\" md\"\"\" Continuous Time Markov Chains What Ben Moll calls finite state Poisson processes Background material QuantEcon lecture notes https continuous time mcs.quantecon.org intro.html Wikipedia https en.wikipedia.org wiki Continuous time Markov chain \"\"\" jumps 0 5 4 0 0 5 0 5 4 0 5 9 0 9 5 0 4 5 0 5 0 0 4 5 0 md\"\"\" The intensity matrix ``Q`` ``Q`` satisfies that ``Q i,j \\geq 0`` for ``i \\ne j`` and ``Q ii \\sum j \\ne i Q ij ``. For a small time interval ``\\Delta t`` and ``i \\ne j`` the intensity ``Q ij `` determines the probability of jumping from ``i`` to ``j`` within that interval ``\\Pr \\Delta t j | i ‚âà \\Delta t \\cdot Q i,j ``. \"\"\" begin Q copy jumps for i ‚àà 1 size Q, 1 Q i,i sum Q i, end Q end let i 2 j 3 Œît 0.01 Œît Q i,j end md\"\"\" Naively Simulating the CTMC \"\"\" ts let T 10 Œît 0.01 ts 0 Œît T end function simulate Q, ts, s‚ÇÄ states 1 size Q, 1 Œît diff ts s s‚ÇÄ out t 0.0, it 1, s for it ‚àà 2 length ts t ts it x rand otherstates filter s , states probs Q s, otherstates . Œît it 1 cumprobs cumsum probs for i, s next ‚àà enumerate otherstates if x cumprobs i s s next break end end push out, t, it, s end out end df ctmc let N 10000 s‚ÇÄ 3 initial state dfs map 1 N do i simulate Q, ts, s‚ÇÄ | DataFrame end vcat dfs..., source i 1 N end let N 10 T 1 title L\"Plotting % N sample paths on t ‚àà 0, % T \" chain df ctmc begin subset i ‚â§ N subset t ‚â§ T data mapping t, s, color i nonnumeric visual Lines draw axis title end end let N length unique df ctmc.i title \"Plotting frequencies over time\" chain df ctmc begin groupby t, s combine frequency length s N unstack s, frequency, fill 0.0 stack Not t , variable name state, value name frequency data mapping t, frequency, color state visual Lines draw axis title end end md\"\"\" Using the Kolmogorov Forward Equation Let ``\\pi t`` be the probability mass function that describes the cross sectional distribution of the CTMC at time ``t``. Then the evolution of the distribution over time is given by the Kolmogorov Forward equation. ```math \\begin align \\dot g t & Q' g t \\\\ \\implies \\frac g t \\Delta t g t \\Delta t &\\approx Q' g t \\\\ \\implies g t \\Delta t &\\approx g t \\Delta t Q' g t I \\Delta t Q' g t \\end align ``` \"\"\" let n size Q, 2 œÄ zeros n œÄ 1 1.0 Œîts diff ts df DataFrame t ts 1 , œÄ, i 1 n dfs df for tm1, Œît ‚àà enumerate Œîts t tm1 1 œÄ I Œît Q' œÄ df DataFrame t, œÄ, i 1 n push dfs, df end data vcat dfs... mapping t, œÄ, color i nonnumeric visual Lines | draw end md\"\"\" Diffusion processes Diffusion processes are continuous time Markov processes with continuous sample paths no jumps . ```math d X t \\underbrace \\mu X t \\text drift dt \\underbrace \\sigma X t \\text volatility d W t, \\qquad X 0 \\text given ``` where ``W t`` is a Wiener process or Brownian motion . Example Ornstein Uhlenbeck process https en.wikipedia.org wiki Ornstein%E2%80%93Uhlenbeck process ```math d X t \\theta \\mu X t dt \\sigma d W t, \\qquad X 0 \\text given ``` \"\"\" Base. kwdef struct OUProcess Œº 0.1 œÉ 0.1 Œ∏ 0.9 end drift x, Œº, œÉ, Œ∏ OUProcess Œ∏ Œº x volatility x, Œº, œÉ, Œ∏ OUProcess œÉ dW Œî Œî randn oup OUProcess md\"\"\" Naive simulations \"\"\" md\"\"\" Using the Kolmogorov Forward Equation Diffusion processes can be represented by their infinitesimal generator https en.wikipedia.org wiki Infinitesimal generator stochastic processes . The discretized version of such a infinitesimal generator looks just like a transition matrix of a CTMC. It turns out that we can use it to simulate and solve the Kolmogorov forward equation. \"\"\" xs, dp let xs range 0.5, 0.5, 50 dp DiffusionProcess xs, drift. xs, Ref oup , volatility. xs, Ref oup xs, dp end df dp let TT typeof it 1, t 1.0, i 1, X 1.0 out TT for i, x‚ÇÄ ‚àà enumerate xs use each gridpoint as initial value once X x‚ÇÄ push out, it 1, t ts 1 , i, X for itm1, Œît ‚àà enumerate diff ts it itm1 1 X X drift X, oup Œît volatility X, oup dW Œît push out, it, t ts itm1 , i, X end end DataFrame out end chain df dp begin subset i % 10 0 data mapping t, X, color i, group i nonnumeric visual Lines draw end chain df dp begin subset it 1 || it % 100 0 data mapping X, group t nonnumeric, color t nonnumeric AlgebraOfGraphics.density draw end generator dp let n length xs œÄ fill 1 n, length xs initial distribution Q generator dp œÄs œÄ Œît 0.01 fig Figure ax Axis fig 1,1 for i ‚àà 1 1000 if i‚àà 1,5,10 || i % 20 0 lines ax, xs, œÄ end œÄ I Œît Q' œÄ push œÄs, œÄ end fig end lines xs, stationary distribution dp md\"\"\" Appendix \"\"\" TableOfContents "},{"url":"housing/housing/","title":"Simple Housing","tags":["housing"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 4 section 1 order 1 title \"Simple Housing\" layout \"layout.jlhtml\" tags \"housing\" description \"\" using Markdown using InteractiveUtils using Optim using QuantEcon using DataFrames, Chain, DataFrameMacros using CairoMakie, AlgebraOfGraphics using AlgebraOfGraphics draw using StatsBase weights using PlutoUI md\"\"\" danger \"Under construction \" This notebook is not ready for public consumption. Use at your own risk. \"\"\" md\"\"\" `housing.jl` | Version 0.1 | last updated Mar 28 2022 \"\"\" md\"\"\" ```math \\begin align &\\max \\operatorname E 0\\Bigl \\sum t 0 ^\\infty \\beta^t u c t, h t \\Bigr \\\\ &\\begin aligned \\text subject to &u c, h h^\\xi c^ 1 \\xi \\\\ &c t p h t a t p h t 1 1 \\delta a t 1 1 r y t \\cdot w \\\\ &\\log y t \\sim \\text some Markov Chain \\\\ &y 0, k 1 , h 1 \\text given \\end aligned \\end align ``` What needs to be specified parameter ``\\delta``, ``\\xi`` prices ``r``, ``w`` idiosynchratic productivity process initial state `` y 0, k 1 `` \"\"\" md\"\"\" Setting up the recursive problem Naive way two endogenous states ```math \\begin align \\tilde s t & a t 1 , h t 1 , y t \\\\ \\tilde a t & a t , h t \\\\ c \\tilde s, \\tilde a & y t \\cdot w \\underbrace a t 1 1 r p h t 1 1 \\delta \\omega t p h t a t \\\\ r \\tilde s, a, h & u c \\tilde s, \\tilde a , h \\\\ q \\underbrace \\cdot, \\cdot, y t \\tilde s t , \\underbrace \\hat a t, \\hat h t \\tilde a t , \\underbrace a t, h t, y t 1 \\tilde s t 1 & \\begin cases \\Pr y t | y t 1 &\\text if \\hat a t a t \\text and \\hat h t h t\\\\ 0 & \\text otherwise \\end cases \\end align ``` \"\"\" md\"\"\" Sophisticated way one endogenous state, two actions Only possible if housing perfectly liquid i.e. no adjustment frictions ```math \\begin align \\tilde s t & \\omega t, y t \\\\ \\tilde a t & a t , h t \\\\ c \\tilde s, \\tilde a & y t \\cdot w \\omega t a t p h t \\\\ r \\tilde s, a, h & u c \\tilde s, \\tilde a , h \\\\ q \\underbrace \\cdot, y t \\tilde s t , \\underbrace a t, h t \\tilde a t , \\underbrace \\omega t 1 , y t 1 \\tilde s t 1 & \\begin cases \\Pr y t | y t 1 &\\text if \\omega t 1 a t 1 r 1 \\delta ph t\\\\ 0 & \\text otherwise \\end cases \\end align ``` \"\"\" md\"\"\" Sophisticated way one endogenous state, one action Only possible if housing perfectly liquid i.e. no adjustment frictions preferences are simple enough ```math \\begin align \\tilde s t & \\omega t, y t \\\\ \\tilde a t & \\omega t 1 \\\\ c \\tilde s, \\tilde a & y t \\cdot w \\omega t a t p h t \\\\ r \\tilde s, \\omega t 1 & u c \\tilde s, \\tilde a , h \\tilde s, \\tilde a \\\\ q \\underbrace \\cdot, y t \\tilde s t , \\underbrace a t, h t \\tilde a t , \\underbrace \\omega t 1 , y t 1 \\tilde s t 1 & \\begin cases \\Pr y t | y t 1 &\\text if \\omega t 1 a t 1 r 1 \\delta ph t\\\\ 0 & \\text otherwise \\end cases \\end align ``` \"\"\" Œæ 0.3 md\"\"\" Setting up the `DDP` \"\"\" md\"\"\" Reward `R` \"\"\" function consumption œâ, z , œâ next , h next, r, w, p , Œ¥ œâ œâ next 1 r z w p h next 1 1 Œ¥ 1 r end a next œâ next , h next, p, r , Œ¥ œâ next p 1 Œ¥ h next 1 r function consumption2 œâ, z , policy, h next, prices, params a next a next policy, h next, prices, params w, p prices z w œâ a next p h next end h max œâ next , p, r , œï, Œ¥ max œâ next 1 Œ¥ 1 r œï , eps function reward etc state, policy, h next, prices, params u a n a next policy, h next, prices, params c consumption state, policy, h next, prices, params c2 consumption2 state, policy, h next, prices, params a next a n assert c ‚âà c2 reward u c, h next , c, h next, a next a n, policy... end function setup R etc R, etc, states, policies, prices, params u for i state, state ‚àà enumerate states for i policy, policy ‚àà enumerate policies hÃÑ h max policy, prices, params res maximize h next reward etc state, policy, h next, prices, params u .reward, eps , hÃÑ h opt Optim.maximizer res out reward etc state, policy, h opt, prices, params u R i state, i policy out.reward etc i state, i policy out..., hÃÑ end end end md\"\"\" Transitions `Q` \"\"\" function setup Q Q, states indices, policies indices, z chain for i next state, next ‚àà enumerate states indices for i policy, œâ next i ‚àà enumerate policies indices for i state, z i ‚àà enumerate states indices if next.œâ i œâ next i Q i state, i policy, i next state z chain.p z i, next.z i end end end end return Q end function setup Q states indices, policies indices, z chain Q zeros length states indices , length policies indices , length states indices setup Q Q, states indices, policies indices, z chain Q end md\"\"\" Solve `DDP` \"\"\" Œµ 0.25 z chain MarkovChain 1 Œµ Œµ 2 Œµ 2 Œµ 2 1 Œµ Œµ 2 Œµ 2 Œµ 2 1 Œµ , 1.25, 1.0, 0.75 function statespace œâ vals range 1e 10, 20.0, length 200 , z chain states œâ, z for œâ ‚àà œâ vals, z ‚àà z chain.state values | vec states indices œâ i, z i for œâ i ‚àà 1 length œâ vals , z i ‚àà 1 length z chain.state values | vec policies œâ next for œâ next ‚àà œâ vals | vec policies indices œâ next i for œâ next i ‚àà 1 length œâ vals | vec states, states indices, policies, policies indices, z chain end function make u Œæ, œÉ function u c, h if c 0 && h 0 C c^ 1 Œæ h^Œæ œÉ 1 ? log C C^ 1 œÉ 1 œÉ else h 0 Inf h^Œæ 100 c 100 end end end function Household œÉ 2.0, Œæ 0.3, Œ≤ 0.96, u make u Œæ, œÉ Œ≤, u end household Household Œî 0.01 make u Œæ 0.5, œÉ 2.0 2 Œî, 0.01 Œî 1.0 params Œ¥ 0.02, œï 0.8 function setup R etc states, policies, prices, parms u proto reward etc first states , first policies , 0.01, prices, params u T typeof proto..., hÃÑ 0.1 etc Array T undef, length states , length policies R zeros length states , length policies setup R etc R, etc, states, policies, prices, params u R, etc end function setup DDP household, statespace, prices, params Œ≤, u household states, policies, states indices, policies indices, z chain statespace Rewards and policies R, etc setup R etc states, policies, prices, params u Transition function Q setup Q states indices, policies indices, z chain ddp DiscreteDP R, Q, Œ≤ ddp, R, etc end md\"\"\" Analyze results \"\"\" function solve details0 ddp, statespace, other policies solver PFI results QuantEcon.solve ddp, solver states, policies statespace opp DataFrame other policies i, s for i, s ‚àà enumerate results.sigma df hcat DataFrame states , DataFrame policies results.sigma , opp, makeunique true df.value results.v df.state states df.policy policies results.sigma df.additional policies other policies results.sigma df.œÄ only stationary distributions results.mc df, results end function solve details ddp, statespace, additional policies solver PFI df solve details0 ddp, statespace, additional policies solver chain df begin transform consumption consumption state, policy, prices transform saving œâ next œâ select Not state, policy, additional policies end end md\"\"\" Equilibrium \"\"\" prices p 2.0, r 0.05, w 1.0 reward etc œâ 2, z 1 , œâ next 2.8 , 1.0, prices, params u make u Œæ 0.5, œÉ 2 œâ grid range 0.1, 10, length 200 ss statespace œâ vals œâ grid, z chain R, ddp, etc setup DDP household, ss, prices, params policies df mapreduce vcat, enumerate eachrow etc do i, row df DataFrame row df.state . i df end chain policies df begin subset state % 10 0 subset reward Inf stack c, h next, a next, reward data mapping œâ next, value, layout variable, color state nonnumeric visual Lines draw facet linkyaxes false, end results df solve details ddp, ss, etc let fg chain results df begin stack Not œâ, z, œÄ a next, consumption, saving data mapping œâ L\"current assets \\omega \", value \"policy\", layout variable, color z nonnumeric, visual Lines draw facet linkyaxes false, , legend position top, titleposition left end ax content fg.figure 2,1 abline ax, 0, 1, color gray, linestyle dash, loose fg end chain results df begin data mapping œâ, œÄ, color z nonnumeric visual Lines draw end chain results df begin stack a next, h next, œâ next , œÄ data mapping value, weights œÄ, layout variable AlgebraOfGraphics.density draw facet linkyaxes false, linkxaxes false end H 1 function aggregates results chain results begin stack Not œÄ groupby variable combine aggregate sum value, weights œÄ zip .variable, .aggregate Dict end end agg aggregates results df h agg \"h next\" , a agg \"a next\" md\"\"\" Appendix \"\"\" TableOfContents "},{"url":"julia-basics/basic-julia/","title":"Basic Julia","tags":["julia-basics"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 1 section 1 order 1 title \"Basic Julia\" layout \"layout.jlhtml\" tags \"julia basics\" description \"\" using Markdown using InteractiveUtils using PlutoUI md\"\"\" `basic julia.jl` | Version 1.2 | last updated Feb 3 2022 \"\"\" md\" A first glance at the Julia language This notebook briefly summarizes some of the basic Julia syntax that we will need for the problem sets. \" Markdown.MD Markdown.Admonition \"warning\", \"This notebook is taken from\", md\"\"\" Computational Thinking , a live online Julia Pluto textbook. computationalthinking.mit.edu https computationalthinking.mit.edu , original notebook https github.com mitmath 18S191 blob Fall20 lecture notebooks Basic%20Julia%20syntax.jl \"\"\" md\" Variables We can define a variable using ` ` assignment . Then we can use its value in other expressions \" x 3 y 2x md\"By default Julia displays the output of the last operation. You can suppress the output by adding ` ` a semicolon at the end. \" md\"We can ask what type a variable has using `typeof` \" typeof y md\" Functions\" md\"We can use a short form, one line function definition for simple functions \" f x 2 x md\"Typing the function's name gives information about the function. To call it we must use parentheses \" f f 10 md\"For longer functions we use the following syntax with the `function` keyword and `end` \" function g x, y z x y return z^2 end g 1, 2 md\" For loops\" md\"Use `for` to loop through a pre determined set of values \" let s 0 for i in 1 10 s s i end s end md\"Here, `1 10` is a range representing the numbers from 1 to 10 \" typeof 1 10 md\"Above we used a `let` block to define a new local variable `s`. But blocks of code like this are usually better inside functions, so that they can be reused. For example, we could rewrite the above as follows \" function mysum n s 0 for i in 1 n s s 1 end return s end mysum 100 md\" Conditionals `if`\" md\"We can evaluate whether a condition is true or not by simply writing the condition \" a 3 a 5 md\"We see that conditions have a Boolean `true` or `false` value. We can then use `if` to control what we do based on that value \" if a 5 \"small\" else \"big\" end md\"\"\"Note that the `if` also returns the last value that was evaluated, in this case the string `\"small\"` or `\"big\"`, Since Pluto is reactive, changing the definition of `a` above will automatically cause this to be reevaluated \"\"\" md\" Arrays\" md\" 1D arrays `Vector`s \" md\"We can make a `Vector` 1 dimensional, or 1D array using square brackets \" v 1, 2, 3 typeof v md\"The `1` in the type shows that this is a 1D array. We access elements also using square brackets \" v 2 v 2 10 md\"Note that Pluto does not automatically update cells when you modify elements of an array, but the value does change.\" md\"A nice way to create `Vector`s following a certain pattern is to use an array comprehension \" v2 i^2 for i in 1 10 md\" 2D arrays matrices \" md\"We can make small matrices 2D arrays with square brackets too \" M 1 2 3 4 typeof M md\"The `2` in the type confirms that this is a 2D array.\" md\"This won't work for larger matrices, though. For that we can use e.g.\" zeros 5, 5 md\"Note that `zeros` gives `Float64`s by default. We can also specify a type for the elements \" zeros Int, 4, 5 md\"We can then fill in the values we want by manipulating the elements, e.g. with a `for` loop.\" md\"A nice alternative syntax to create matrices following a certain pattern is an array comprehension with a double `for` loop \" i j for i in 1 5, j in 1 6 md\"\"\" Appendix \"\"\" TableOfContents "},{"url":"julia-basics/more-julia/","title":"More Julia","tags":["julia-basics"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 1 section 2 order 1 title \"More Julia\" layout \"layout.jlhtml\" tags \"julia basics\" description \"\" using Markdown using InteractiveUtils using DataFrames using DataFrameMacros using Chain chain using PlutoUI md\"\"\" `more julia.jl` | Version 1.1 | last updated May 10 2022 | created by Daniel Schmidt https github.com danieljschmidt \"\"\" md\"\"\" More Julia \"\"\" md\"\"\" The purpose of this notebook is to make you familiar with Julia syntax that is frequently used in the course material. It also points out the peculiarities of Pluto notebooks. \"\"\" md\"\"\" Named tuples and keyword arguments Named tuples Like many other programming languages, Julia allows you to create tuples. The elements of tuples can be accessed by using the corresponding index \"\"\" standard tuple 1, 2 standard tuple 1 md\"\"\" Julia also has named tuples. Just like standard tuples, named tuples allow you to access an element using its index, but alternatively you can also access an element by its name. \"\"\" named tuple a 1, b 2 named tuple.a md\"\"\" This is convenient because it means that you do not need to remember if some parameter is the first element in a tuple or the second one. Below you can see an alternative way of creating named tuples that is frequently used in the course material \"\"\" let a 1 named tuple2 a, b 2 a is equivalent to a a end md\"\"\" Keyword arguments A similar syntax with a semicolon is used for keyword arguments that are identified by name and not by their position as normal function arguments \"\"\" function some function a, b 1 return a b end some function a 3, b 5 let a 3 some function a, b 5 a is equivalent to a a end md\"\"\" Vectorization with dot syntax You can apply a function to all elements of a vector by using the dot syntax \"\"\" 1,2,3 .^ 2 log. 1,2,3 md\"\"\" Note how Julia usually does things in a way that's mathematically consistent. Look at the following code. \"\"\" A ones 3, 3 exp A exp. A A^2 A .^ 2 md\"\"\" What would Python, R or Matlab do? \"\"\" md\"\"\" The pipe operator The pipe operator | makes it possible to write down nested function calls in a more readable way. For example, the two expressions below do the same thing \"\"\" round log named tuple.b named tuple.b | log | round md\"\"\" In case you use R The | operator in Julia is similar to the % % operator in R. \"\"\" md\"\"\" Unicode characters You can use Greek letters and other Unicode characters in your Julia code. For example, type \"\\alpha\" in the cell below without the quotation marks and press Tab on your keyboard. This should create an \\alpha symbol. \"\"\" md\"\"\" See the Julia documention https docs.julialang.org en v1 manual unicode input for a list of supported Unicode characters. For Greek letters, the abbreviations are the same as in LaTeX. \"\"\" md\"\"\" The \\in symbol An elegant way of writing loops is to use the \\in symbol instead of writing \"in\". The \\in symbol can be created by typing \"\\in\" and pressing Tab. \"\"\" i^2 for i ‚àà 1 5 md\"\"\" Working with data Here are a few simple examples of working with DataFrames in Julia. If you are familiar with pandas, dplyr or Stata, have a look at this cheatsheet https dataframes.juliadata.org stable man comparisons . Also, have a look at the documentation of DataFrameMacros.jl https jkrumbiegel.github.io DataFrameMacros.jl stable which makes working with DataFrames much more convenient. \"\"\" md\"\"\" Creating a `DataFrame` \"\"\" df1 DataFrame x 1 10 md\"\"\" Transforming mutating a column \"\"\" transform df1, x ByRow x sqrt x transform df1, sqrt x uses transform from DataFrameMacros.jl md\"\"\" The ``` chain``` macro \"\"\" md\"\"\" The ``` chain``` macro works similar to the pipe operator. In the code for this course, the ``` chain``` macro is often applied to data frames together with macros from the ```DataFrameMacros``` package. \"\"\" df2 DataFrame A 1,2,2,1 , B randn 4 md\"\"\" Consider the data frame above. Let's say you would like to add up the values in the B column separately for each value of A take the absolute value of the resulting sums of B values. Using the ``` chain``` macro, we can perform this task with relatively concise code \"\"\" chain df2 begin groupby A combine sum B , automatically named C sum B specify name transform abs C end md\"\"\" Without the ``` chain``` macro, the code would look like this \"\"\" begin df groups groupby df2, A df sum combine df groups, sum B , C sum B transform df sum, abs C end md\"\"\" Pluto notebooks General advice Press F1 to see shortcuts for Pluto notebooks. Ctrl Click on an underlined variable or function to jump to its definition. Use the Live docs in the bottom right corner to get more information about any Julia function or object. Check the Github wiki https github.com fonsp Pluto.jl wiki for more information on Pluto notebooks. Automated updating of cells When changing a function or variable, Pluto automatically updates all affected cells. For example, change the value of d to some other number and see how the following cell updates automatically \"\"\" d 5 d 10 md\"\"\" This is different from jupyter notebooks in which you have to update related cells manually. The automated updating the advantage that you do not have to keep in mind the order in which to evaluate cells. However, it can also be annoying if some of the affected cells take a long time to run. At the time of writing, there is no way to turn off the automated updating but you can always manually disable cells with long run times by clicking on the three dots in the top right corner of a cell. \"\"\" md\"\"\" Only one expression per cell Pluto notebooks only allow one expression per cell. If you nevertheless want to place several expressions into the same cell, you have to use a begin ... end block \"\"\" begin e 10 f e 5 end md\"\"\" Cannot reuse variable names \"\"\" md\"\"\" Use `let` blocks to specify variable names locally. \"\"\" let g 3 end g md\"\"\" Deactivate cells \"\"\" ‚ï†‚ïê‚ï° sleep 5 ‚ï†‚ïê‚ï° md\"\"\" Imported Packages \"\"\" TableOfContents g 1 g 2 "},{"url":"long-run/redistributive-growth/","title":"Redistributive growth","tags":["long-run"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 5 section 3 order 3 title \"Redistributive growth\" layout \"layout.jlhtml\" tags \"long run\" description \"\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end using PlutoUI using PlutoUI Slider using DataFrames using CairoMakie using ForwardDiff using Optim using LaTeXStrings md\"\"\" `redistributive growth.jl` | Version 1.2 | last updated on May 10, 2023 \"\"\" md\"\"\" Redistributive Growth This lecture is based on the paper Redistributive Growth D√∂ttling and Perotti 2019 . This paper tries to explain various macroeconomic trends with a technological shift to intangible capital. \"\"\" md\"\"\" Parameterization \"\"\" md\"\"\" We use a slight variation of the parameterization in the September 2019 version of the paper. The utility from housing is v L \\log L . \"\"\" Base. kwdef struct RedistributiveGrowthModel LÃÑ 1 supply of land œï 0.2 fraction with high human capital hÃÉ 8 0.2 inelastic supply of high skilled labor lÃÉ 10 1 0.2 inelastic supply of low skilled labor Œ± 0.33 capital share Œ∑ 0.45 relative productivity of intangible capital & high skilled labor œâ 0.9 fraction of intangibles that can be \"stolen\" by innovators œà 1. cost for producing intangibles A 1. productivity end mod RedistributiveGrowthModel md\"\"\" Representative firm \"\"\" md\"\"\" We consider the special case \\rho \\rightarrow 0 in which the production function has a Cobb Douglas form Y F K, H, l, h A H^\\alpha h^ 1 \\alpha ^\\eta K^\\alpha l^ 1 \\alpha ^ 1 \\eta \"\"\" function F K, H, l, h, A, Œ∑, Œ± A H^Œ± h^ 1 Œ± ^Œ∑ K^Œ± l^ 1 Œ± ^ 1 Œ∑ end md\"\"\" 1. Productivity of intangible capital \\eta bind Œ∑ sl Slider range 0, 1, length 101 , default 0.5, show value true 2. Capital share \\alpha bind Œ± sl Slider range 0, 1, length 101 , default 0.5, show value true 3. Common productivity factor A bind A sl Slider 1 100, default 1, show value true \"\"\" md\"\"\" Labor is supplied inelastically in this model so that l 1 \\phi \\tilde l and h \\phi \\tilde h . Therefore, we can write down the production function as a function of only K and H \"\"\" function F K, H, A, Œ∑, Œ±, œï, lÃÉ, hÃÉ l 1 œï lÃÉ h œï hÃÉ F K, H, l, h, A, Œ∑, Œ± end md\"\"\" We can compute the first derivatives of the production function numerically which correspond to the factor prices price of physical capital 1 r price of intangible capital R H wage for manual workers w wage for high skill workers q \"\"\" F xx, par F xx..., par let Hs Ks range 0.01, 1, length 101 title latexstring \"Contour plot of \\ Y K, H, l 1, h 1 \\ \" fig Figure ax, plt contourf fig 1,1 , Hs, Ks, x, y F x, y, 1., 1., A A sl, Œ∑ Œ∑ sl, Œ± Œ± sl , axis title, xlabel L\"K\", ylabel L\"H\" Colorbar fig 1,2 , plt fig end function get prices K, H, mod œï, lÃÉ, hÃÉ mod l 1 œï lÃÉ h œï hÃÉ xx K, H, l, h oneplusr, R H, w, q ForwardDiff.gradient x F x, mod , xx Y F xx, mod check Y w l q h oneplusr K R H H check, oneplusr, R H, w, q, Y end get prices 0.5, 1., mod md\"\"\" Steady state equilibrium \"\"\" md\"\"\" The equations that describe the steady state values of \\ K, H, Y, r, R H, f, p\\ together with the production function are given in the appendix of the paper 1 r \\alpha 1 \\eta \\frac Y K R H \\alpha \\eta \\frac Y H H \\frac \\omega \\psi R H f \\frac 1 \\omega R H H r p \\frac v' \\bar L r \\frac 1 \\bar L r 1 \\alpha Y p \\bar L f K \"\"\" md\"\"\" Exercise 1 3 points üëâ Provide brief derivations for equation 1 1 point and equation 4 2 points above. \"\"\" md\"\"\" Your answer goes here ... \"\"\" md\"\"\" Solving for the steady state \"\"\" md\"\"\" We use numerical methods to solve for the steady state. First, we reformulate the system of equations by substituting out the five variables \\ Y, r, R H, f, p\\ , so that we end up with a system of just two equations as a function of K and H \"\"\" function model equations 1 K, H, mod Œ±, Œ∑, œâ, LÃÑ, œï, lÃÉ, A mod Y F K, H, mod production function r Œ± 1 Œ∑ Y K 1 eq. 1 rearranged R H Œ± Œ∑ Y H eq. 2 f 1 œâ R H H r eq. 4 p 1 LÃÑ r eq. 5 return Y, r, R H, f, p end function model equations 2 K, H, mod Y, r, R H, f, p model equations 1 K, H, mod Œ±, œâ, LÃÑ, œà mod eq 1 H œâ œà R H eq. 3 rearranged eq 2 1 Œ± Y p LÃÑ f K eq. 6 rearranged return eq 1, eq 2 end md\"\"\" ```eq 1``` and ```eq 2``` in the function above should be zero at the steady state values of K and H . Consequently, the sum of the squares ```eq 1```¬≤ ```eq 2```¬≤ should also be zero in this case. This means that we can find the steady state values of K and H by applying a minimization algorithm to ```eq 1```¬≤ ```eq 2```¬≤. To make sure that the algorithm does not accidentally use negative values for K or H , we write down the objective function in terms of \\log K and \\log H . After running the minimization algorithm, we always need to check if the sum of squares is indeed zero or at least extremely close to zero . Other solution algorithms are possible and probably better than this approach. See this notebook https greimel.github.io distributional macroeconomics notebooks redistributive growth fabian with alternative solution methods for the redistributive growth model. \"\"\" function objective function log K log H, mod K exp log K log H 1 H exp log K log H 2 eq 1, eq 2 model equations 2 K, H, mod return eq 1^2 eq 2^2 end md\"\"\" We need to initialize the minimization algorithm at values for K and H that are associated with a positive interest rate r . Otherwise, the algorithm may converge to another minimum with a negative interest rate that is not economically meaningful. Below you can see that the interest rate associated with our starting values is indeed positive. \"\"\" begin K init 0.4 H init 1. model equations 1 K init, H init, mod end md\"\"\" Now we apply the minimization algorithm. The objective function is very close to 0 at the minimum that the algorithm found. \"\"\" res optimize x objective function x, mod , log K init , log H init md\"\"\" Since the arguments of the objective function are \\log K and \\log H , we need to exponentiate the minimizer to get the steady state values of K and H \"\"\" K, H exp. Optim.minimizer res md\"\"\" To find the steady state values of \\ Y, r, R H, f, p\\ , we put the steady state values of K and H into the equations that we have used to substitute out these five variables \"\"\" model equations 1 K, H, mod md\"\"\" Moreover, we can get steady state wages w and q by computing the numerical gradient of the production function \"\"\" get prices K, H, mod md\"\"\" Exercise 2 1 point The steady state interest rate r round model equations 1 K, H, mod .r 100,digits 1 % seems quite big at a first glance. üëâ Is steady state interest rate in the model roughly consistent with interest rates in the real world? Provide a brief explanation. max. 100 words \"\"\" answer 2 md\"\"\" Your answer goes here ... \"\"\" md\"\"\" Secular trends \"\"\" md\"\"\" The paper claims that a shift towards intangible capital \\eta \\uparrow in the model can explain the following macroeconomic trends declining interest rates r \\downarrow increasing share of intangible capital H H K \\uparrow declining physical investment scaled by GDP K Y \\downarrow increasing mortgage borrowing m Y \\uparrow increasing house prices p Y \\uparrow increasing stock prices f Y \\uparrow increasing wage inequality q w \\uparrow \"\"\" md\"\"\" To confirm that an increase in \\eta indeed generates the secular trends listed above for the given parameterization, we compute the steady state for a slightly higher value of \\eta such as \\eta round mod.Œ∑ 0.1, digits 2 and compare the variables of interest in the two steady states. \"\"\" mod Œ∑ RedistributiveGrowthModel Œ∑ mod.Œ∑ 0.1 model equations 1 K init, H init, mod Œ∑ res Œ∑ optimize x objective function x, mod Œ∑ , log K init , log H init K Œ∑, H Œ∑ exp. Optim.minimizer res Œ∑ md\"\"\" The first row describes the steady state for the baseline value for \\eta , the second row for \\eta round mod Œ∑.Œ∑, digits 3 \"\"\" md\"\"\" Below you can find two helper functions to compute the macroeconomic variables of interest for given steady state values K , H , and to compare macroeconomic variables across steady states \"\"\" function compute trends variables K, H, mod Y, r, R H, f, p model equations 1 K, H, mod œï, LÃÑ, lÃÉ mod w, q get prices K, H, mod m max 0, 1 œï p LÃÑ f w lÃÉ H HK H H K K Y K Y m Y m Y p Y p Y f Y f Y q w q w r, H HK, K Y, m Y, p Y, f Y, q w end begin trends vars compute trends variables K, H, mod trends vars Œ∑ compute trends variables K Œ∑, H Œ∑, mod Œ∑ DataFrame trends vars, trends vars Œ∑ end function trends trends vars 1, trends vars 0 for key in keys trends vars 0 if trends vars 1 key trends vars 0 key 1e 6 sgn \"‚Üë\" elseif trends vars 1 key trends vars 0 key 1e 6 sgn \"‚Üì\" else sgn \"‚Üí\" end println key, \" \" , sgn end end trends trends vars Œ∑, trends vars md\"\"\" Alternative growth drivers \"\"\" md\"\"\" In the previous section, we found out that a technological shift to intangible capital \\eta \\uparrow can explain the secular trends at least qualitatively . But is it the only possible explanation of these trends? In order to exclude other possible explanations, we need to consider alternative growth drivers and check which of the secular trends they can replicate and which not. The following alternative growth drivers are already implemented in the model greater ease of innovation \\psi \\downarrow rising share of educated workers \\phi \\uparrow rising productivity of capital relative to labor \\alpha \\uparrow increased bargaining power for innovators over established firms \\omega \\uparrow \"\"\" md\"\"\" Exercise 3 2.5 points üëâ Pick one of the four alternative growth drivers listed above and conduct a comparison of steady states similar to the \\eta \\uparrow case. Which of the secular trends can this growth driver explain and which not? Provide a brief explanation for the changes in \\ r, H H K , K Y, m Y, p Y, f Y, w q\\ that are generated by the parameter change that you consider. max. 200 words \"\"\" Your code goes here ... answer 3 md\"\"\" Your answer goes here ... \"\"\" md\"\"\" Exercise 4 3.5 points An alternative growth driver are capital inflows from emerging countries into the developed world \"global savings glut\" . These capital inflows can be incorporated into the model by adding an exogenous increase in savings x to the steady state equations 1 \\alpha x Y p \\bar L f K üëâ Add the exogenous increase in savings to the model and repeat exercise 3 for this alternative growth driver. max. 200 words \"\"\" Your code goes here ... answer 4 md\"\"\" Your answer goes here ... \"\"\" md\"\"\" Before you submit ... üëâ Make sure you do not mention your name in the assignment. The assignments are graded anonymously. üëâ Make sure that that all group members proofread your submission. üëâ Make sure all the code is well documented . üëâ Make sure that you are within the word limit . Short and concise answers are appreciated. Answers longer than the word limit will lead to deductions. üëâ Go to the very top of the notebook and click on the symbol in the very top right corner. Export a static html file of this notebook for submission. The source code is embedded in the html file. \"\"\" md\"\"\" Appendix \"\"\" md\"\"\" Acknowledgments The visualization of the production function was contributed by Andrea Titton https github.com NoFishLikeIan . \"\"\" md\"\"\" Word limit functions \"\"\" function wordcount text stripped text strip replace string text , r\"\\s\" \" \" words split stripped text, ' ', ' ', '.', ',', ' ', ' ', '\"', ' ', ' ', '\\'' length filter \"\" , words end show words answer md\" approximately wordcount answer words \" begin admonition kind, title, text Markdown.MD Markdown.Admonition kind, title, text hint text, title \"Hint\" admonition \"hint\", title, text warning text, title \"Warning\" admonition \"warning\", title, text danger text, title \"Danger\" admonition \"danger\", title, text correct text, title \"Correct\" admonition \"correct\", title, text almost text warning text, \"Almost there \" keep working text md\"The answer is not quite right.\" danger text, \"Keep working on it \" yays md\"Great \", md\"Yay ‚ù§\", md\"Great üéâ\", md\"Well done \", md\"Keep it up \", md\"Good job \", md\"Awesome \", md\"You got the right answer \", md\"Let's move on to the next section.\" got it text rand yays correct text, \"Got it \" end function show words limit answer, limit count wordcount answer if count 1.02 limit return show words answer else return almost md\"You are at count words. Please shorten your text a bit, to get below limit words .\" end end show words limit answer 2, 100 show words limit answer 3, 200 show words limit answer 4, 200 md\"\"\" Imported packages \"\"\" TableOfContents "},{"url":"preliminaries/aiyagari/","title":"Aiyagari","tags":["preliminaries"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 2 section 3 order 3 title \"Aiyagari\" layout \"layout.jlhtml\" tags \"preliminaries\" description \"\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end using PlutoUI Button, Slider, TableOfContents, NumberField using AlgebraOfGraphics, CairoMakie using AlgebraOfGraphics draw using DataFrameMacros using Chain chain using DataFrames using DataFrames stack using StatsBase weights using Statistics mean using LinearAlgebra using Roots find zero, Brent using QuantEcon md\"\"\" `aiyagari.jl` | Version 1.1 | last updated May 16, 2022 \"\"\" md\"\"\" Bewley Huggett Aiyagari \"\"\" md\"\"\" Households' problem \"\"\" md\"\"\" ```math \\begin align &\\max \\operatorname E 0\\Bigl \\sum t 0 ^\\infty \\beta^t u c t \\Bigr \\\\ &\\begin aligned \\text subject to &u c \\log c \\\\ &c t k t k t 1 1 r \\delta y t \\cdot w \\\\ &\\log y t \\sim \\text some Markov Chain \\\\ &y 0, k 1 \\text given \\end aligned \\end align ``` What needs to be specified parameter ``\\delta`` prices ``r``, ``w`` idiosynchratic productivity process initial state `` y 0, k 1 `` \"\"\" md\"\"\" Let ``s k, y `` be the state and ``a k' `` be the action. We can then write ```math c s,a \\cdots y \\cdot w k\\cdot 1 r \\delta k' ``` Let us also define the reward function ```math r s, a \\cdots u c s,a \\cdots ``` Rewrite this recursively, ```math \\begin align v s \\max a \\in A r s, a \\operatorname E v s' |s, a \\end align ``` \"\"\" md\"\"\" Setup \"\"\" md\"\"\" To find a solution to the households' problem, we will use the Quantecon toolbox. The toolbox requires us to specify an n \\times m array R that contains the value of the reward function for each state and action R ij r s i, a j an n \\times m \\times n array Q that gives the probability to end up in state s' in the next period for a given state s and action a in this period Q ijk \\text Prob s' s k|s s i, a a j a discount factor \\beta . For more information on this way of formulating Discrete State Dynamic Programming problems, please have a look at the QuantEcon lecture notes https julia.quantecon.org dynamic programming discrete dp.html on this topic. \"\"\" md\"\"\" As a first step, we represent household preferences by a named tuple that contains the discount factor \\beta and the utility function u \\cdot \"\"\" function Household œÉ 1.0, Œ≤ 0.96, u œÉ 1 ? log x x^ 1 œÉ 1 1 œÉ Œ≤, u end md\"\"\" Moreover, the function below constructs the state space for a given grid of asset values ```k vals``` and a given Markov process ```z chain```. The resulting vector of possible states has length n and the vector of possible policies has length m . \"\"\" function statespace k vals range 1e 10, 20.0, length 200 , z chain states k, z for k ‚àà k vals, z ‚àà z chain.state values | vec states indices k i, z i for k i ‚àà 1 length k vals , z i ‚àà 1 length z chain.state values | vec policies k next for k next ‚àà k vals | vec policies indices k next i for k next i ‚àà 1 length k vals | vec states, states indices, policies, policies indices, z chain end md\"\"\" Now we can compute the array of transition probabilities Q If the chosen amount of assets coincides with the amount of assets in the state next period, the transition probability is equal to the transition probability for the productivity process \\text Prob z'|z . In all other cases, the transition probability is zero. \"\"\" function setup Q Q, states indices, policies indices, z chain for i next state, next ‚àà enumerate states indices for i policy, k next i ‚àà enumerate policies indices for i state, z i ‚àà enumerate states indices if next.k i k next i Q i state, i policy, i next state z chain.p z i, next.z i end end end end return Q end function setup Q states indices, policies indices, z chain Q zeros length states indices , length policies indices , length states indices setup Q Q, states indices, policies indices, z chain Q end md\"\"\" Before we can compute the reward array R , we first need a function that can compute consumption for a given state and action. The function below allows for a higher interest rate r \\text borrow r \\Delta r for households with negative assets. \"\"\" function consumption z, k , k next , q, w, Œîr if k next 0 && Œîr 0 r 1 q 1 k next 0 Œîr q 1 1 r end c w z k q k next end function reward state, policy, prices, u c consumption state, policy, prices if c 0 u c else 100 000 100 c end end function setup R R, states, policies, prices, u for k i, policy ‚àà enumerate policies for s i, state ‚àà enumerate states R s i, k i reward state, policy, prices, u end end return R end function setup R states, policies, prices, u R zeros length states , length policies setup R R, states, policies, prices, u end md\"\"\" Finally, we define a function that creates an instance of the ```DiscreteDP``` i.e. Discrete Dynamic Program class for given household preferences, a given state space and given prices. \"\"\" md\"\"\" Model parameters \"\"\" md\"\"\" First, let us define the interest rate, the wage, and the interest wedge for borrowers. We also define functions that turn the interest rate into the price of a bond q . \"\"\" r 0.02 q r 1 1 r prices q q r , w 1.0, Œîr r 2 md\"\"\" Next, we define choose the parameters that govern household preferences. \"\"\" hh Household œÉ 2.0, Œ≤ 0.96 md\"\"\" We also need to define the Markov chain for the productivity process \"\"\" z chain MarkovChain 0.75 0.25 0.25 0.75 , 1.25, 0.75 function setup DDP household, statespace, prices Œ≤, u household states, policies, states indices, policies indices statespace R setup R states, policies, prices, u Q setup Q states indices, policies indices, z chain DiscreteDP R, Q, Œ≤ end md\"\"\" We combine this Markov chain with a grid for assets ```k vals``` to construct the state space. The smallest asset value on the grid defines the maximum amount that a household can borrow. The largest asset value on the grid needs to be large enough so that it does not distort the model solution. \"\"\" ss statespace k vals range 1., 5., length 200 , z chain md\"\"\" As the final step, we create an instance of the ```DiscreteDP``` class for the previously defined parameter values. \"\"\" ddp setup DDP hh, ss, prices md\"\"\" Solve households' problem \"\"\" md\"\"\" We solve the households' problem using the policy function iteration PFI algorithm from the QuantEcon toolbox. In the data frame below, each row corresponds to point in the state space. \\pi denotes the stationary distribution. \"\"\" function solve details0 ddp, states, policies solver PFI results QuantEcon.solve ddp, solver df DataFrame states DataFrame policies results.sigma df.state states df.policy policies results.sigma df.œÄ stationary distributions results.mc , 1 1 df end function solve details ddp, states, policies solver PFI df solve details0 ddp, states, policies solver chain df begin transform consumption consumption state, policy, prices transform saving k next k select Not state, policy end end results solve details ddp, ss.states, ss.policies solver PFI md\"\"\" Policy functions The figure below show how much a household should consume and how much it should save given its current amount of assets and productivity state. \"\"\" let fg chain results begin stack Not k, z, œÄ data mapping k L\"current assets k \", value \"policy\", layout variable, color z nonnumeric, visual Lines draw facet linkyaxes false, , legend position top, titleposition left end ax content fg.figure 2,1 fg end k first chain results begin subset k next k groupby z combine first k end md\"\"\" Below, we compute the lowest asset value at which we observe dissaving by the household. Households in the low productivity state dissave even when they are very close to the borrowing constraint, while households in the high productivity state only start dissaving above an asset level of round k first 1, \"k first\" , digits 3 . \"\"\" md\"\"\" Stationary distribution The figure below depicts the probability density over assets for separately for the two productivity levels. \"\"\" chain results begin data mapping k, œÄ, color z nonnumeric visual Lines draw end md\"\"\" More on the stationary distribution In the first lecture you have learned that the Aiyagari model is a Markov chain with respect to the n \\times n transition matrix Q^ that is implicitly defined by the stochastic income process and the optimal savings rule. Note that Q^ is different from the n \\times m \\times n matrix Q which did not impose the optimal savings rule. In the cell below, we compute Q^ by combining the optimal savings rule with the Q matrix. We also check if the rows of Q^ sum to 1 \"\"\" begin res QuantEcon.solve ddp, PFI Q setup Q ss.states indices, ss.policies indices, ss.z chain Q star 1 zeros length ss.states , length ss.states for i state, state ‚àà enumerate ss.states indices Q star 1 i state, Q i state,res.sigma i state , end sum Q star 1 dims 2 ' end md\"\"\" Within the QuantEcon framework, the Q^ matrix is saved as ```res.mc.p``` where ```res``` is some results object that is returned by the ```QuantEcon.solve``` function. Below, we check if the Q^ matrix computed by us is the same as the Q^ matrix computed by the ```QuantEcon project``` \"\"\" begin Q star 2 res.mc.p isapprox Q star 1, Q star 2 end md\"\"\" If the Markov chain is ergodic, we can obtain the stationary distribution by starting with an arbitray distribution \\pi 1 over the state space and applying the transition matrix to it until the distribution converges to the stationary distribution \\pi \\infty . You can do this using the buttons below Restart Initialize \\pi 1 such that all agents are in the high income state with zero assets Update \\pi i 1 ' \\pi i' \\cdot Q^ Feel free to choose another initialization. Note that Pluto automatically applies one update step after you press \"Restart\". \"\"\" md\"\"\" bind restart dens Button \"Restart\" bind update dens Button \"Update\" \"\"\" begin restart dens j 1 I need to use array here because otherwise Pluto complains that there are multiple definitions of j dist zeros size ss.states dist 1 1. df DataFrame ss.states df.œÄ dist end begin update dens j 1 j 1 1 df.œÄ df.œÄ' Q star 1 ' print j 1 , \" iterations\" chain df begin data mapping k, œÄ, color z nonnumeric visual Lines draw end end md\"\"\" Aggregate outcomes \"\"\" md\"\"\" The function below computes aggregate consumption, aggregate assets etc. Since we assume that there is a probability mass 1 of households, computing the aggregate variables means computing the average over the state space weighted by the stationary distribution of households. \"\"\" function aggregates results chain results begin stack Not œÄ groupby variable combine aggregate sum value, weights œÄ zip .variable, .aggregate Dict end end agg aggregates results md\"\"\" Interactive results \"\"\" md\"\"\" Risk aversion coefficient \\sigma \"\"\" bind œÉ slider Slider 1. 0.25 3., show value true, default 2. md\"\"\" Discount factor \\beta \"\"\" bind Œ≤ slider Slider 0.95 0.005 0.97, show value true, default 0.96 begin hh slider Household œÉ œÉ slider, Œ≤ Œ≤ slider ddp slider setup DDP hh slider, ss, prices results slider solve details ddp slider, ss.states, ss.policies solver PFI end md\"\"\" Aggregate savings round mean results slider.k, weights results slider.œÄ , digits 3 \"\"\" begin fg chain results slider begin stack Not k, z data mapping k \"current assets k\", value, layout variable, color z nonnumeric, visual Lines draw facet linkyaxes false, , legend position top, titleposition left end ax content fg.figure 2,2 ablines ax, 0, 1, color gray, linestyle dash, loose fg end md\"\"\" Huggett equilibrium \"\"\" md\"\"\" Setup To compute the Huggett equilibrium, we need a function that computes the amount of excess savings in the economy for a given interest rate r . \"\"\" function excess savings hh, statespace, r w, Œîr ddp setup DDP hh, statespace, w, q q r , Œîr Œîr results solve details ddp, statespace.states, statespace.policies, solver PFI return Œ∂ mean results.k, weights results.œÄ end Œ∂ r excess savings hh, ss, r, w prices.w, Œîr prices.Œîr md\"\"\" Finding the equilibrium In the Huggett equilribium, the equilibrium interest rate is the interest rate at which the excess savings \\zeta r are zero. To find this interest rate, we use the so called bisection algorithm. \"\"\" md\"\"\" Initial interval for interest rate As a first step, we need to find an interval so that excess savings are positive at one endpoint and negative at the other endpoint. Left endpoint r l bind left NumberField 0.00 0.01 0.04, 0.01 Right endpoint r r bind right NumberField 0.01 0.01 0.04, 0.03 \"\"\" md\"\"\" Excess savings at left endpoint ``\\zeta r l `` round excess savings hh, ss, left prices.w, prices.Œîr , digits 4 right endpoint ``\\zeta r r `` round excess savings hh, ss, right prices.w, prices.Œîr , digits 4 \"\"\" md\"\"\" If you have found such an interval, you can be sure that the excess savings function \\zeta r crosses zero at least once in this interval. This means that we can start the bisection algorithm now. Bisection algorithm One step of the bisection algorithm works as follows compute the midpoint r m 1 2 r l r d if the sign of \\zeta r m is different from the sign of \\zeta r l use the midpoint r m as the right endpoint of the new interval and leave the left endpoint unchanged if the sign of \\zeta r m is different from the sign of \\zeta r r use the midpoint r m as the left endpoint of the new interval and leave the right endpoint unchanged bind start Button \"Restart bisection\" bind go Button \"Bisect the interval\" \"\"\" begin start left vec left right vec right Œ∂ left vec Œ∂ left Œ∂ right vec Œ∂ right if Œ∂ left vec end Œ∂ right vec end 0. throw DomainError left, right , \"Function has the same sign at the left endpoint and at the right endpoint\" end end begin go mid left vec end right vec end 2 Œ∂ mid Œ∂ mid if Œ∂ left vec end Œ∂ mid 0. push left vec, left vec end push Œ∂ left vec, Œ∂ left vec end push right vec, mid push Œ∂ right vec, Œ∂ mid elseif Œ∂ right vec end Œ∂ mid 0. push left vec, mid push Œ∂ left vec, Œ∂ mid push right vec, right vec end push Œ∂ right vec, Œ∂ right vec end else throw DomainError left, right , \"Function has the same sign at the left endpoint and at the right endpoint\" end info left vec end , right vec end f Figure ax1 Axis f 1, 1 , xlabel \"interest rate r\", ylabel \"excess savings Œ∂\" scatter ax1, left vec, Œ∂ left vec scatter ax1, right vec, Œ∂ right vec vspan ax1, left vec end , right vec end , ymin 1., y max 1., color grey, 0.2 r vec vcat left vec, reverse right vec Œ∂ vec vcat Œ∂ left vec, reverse Œ∂ right vec lines ax1, r vec, Œ∂ vec, color \"black\" xlabel ax1, \"excess savings Œ∂\" ylabel ax1, \"interest rate r\" current figure end md\"\"\" Aiyagari equilibrium \"\"\" md\"\"\" Setup \"\"\" md\"\"\" The production function is F K, N A K^\\alpha N^ 1 \\alpha where K is the capital stock and N is labor. \"\"\" function production f, K return f.A K ^ f.Œ± f.N ^ 1 f.Œ± end md\"\"\" The function below creates a named tuple with all parameters that describe the technology of the firm. \"\"\" function Firm A 1, N 1, Œ± 0.33, Œ¥ 0.05 A, N, Œ±, Œ¥ end md\"\"\" From the first order conditions we can derive three functions that will be useful later on the capital demand function and its inverse ```K to r``` a function that computes the wage that is associated with the given interest rate \"\"\" function capital demand f, r K f.Œ± f.A r f.Œ¥ ^ 1 1 f.Œ± f.N return K end function K to r f, K Compute the interest rate that is associated with the given demand for capital return f.A f.Œ± f.N K ^ 1 f.Œ± f.Œ¥ end function r to w f, r Compute the wage that is associated with the given interest rate return f.A 1 f.Œ± f.A f.Œ± r f.Œ¥ ^ f.Œ± 1 f.Œ± end md\"\"\" Model parameters \"\"\" firm Firm md\"\"\" For the household problem, we choose other model parameters than in the Huggett model. Moreover, we use less grid points for assets to make sure that the calibration of \\beta does not take too much time. \"\"\" hh2 Household Œ≤ 0.96, u log ss2 statespace k vals range 1e 10, 20.0, length 100 , z chain MarkovChain 0.9 0.1 0.1 0.9 , 0.1 1.0 md\"\"\" Finding the equilibrium \"\"\" md\"\"\" First, we have a look at the capital demand and supply curves \"\"\" function capital supply hh, f, statespace, r w r to w f, r ddp setup DDP hh, statespace, w, q q r , Œîr 0.0 results solve details ddp, statespace.states, statespace.policies, solver PFI return K mean results.k, weights results.œÄ end begin r vals supply range 0.001, 0.04, length 20 k vals capital supply. Ref hh2 , Ref firm , Ref ss2 , r vals supply r vals demand K to r. Ref firm , k vals end let fig Figure ax fig 1, 1 Axis fig, xlabel \"capital\", ylabel \"interest rate\" lines k vals, r vals demand, label \"demand\" lines k vals, r vals supply, label \"supply\" axislegend fig end function excess demand hh, f, statespace, r supply capital supply hh, f, statespace, r demand capital demand f, r return demand supply end begin initial bracket 0.005, 0.055 r eq find zero r excess demand hh2, firm, ss2, r , initial bracket, Brent k eq capital demand firm, r eq r eq, k eq end md\"\"\" To determine the exact equilibrium interest rate, we apply a root finding algorithm to a function that computes excess demand for capital for a given interest rate. We could of course use the bisection algorithm that we have used to compute the Huggett equilibrium above. But to make sure that the code is fast enough, we take the Brent algorithm https en.wikipedia.org wiki Brent%27s method which is implemented in the ```Roots.jl``` package. Since the household's decision problem needs to be solved for a different value of the interest rate at each step of the algorithm, finding the equilibrium can be time consuming, especially in more complicated models. The resulting equilibrium interest rate is round r eq, digits 4 and the associated capital stock is round k eq, digits 3 . \"\"\" wto target 3.63 md\" Calibrating the discount factor \\beta Now, let's choose the discount factor \\beta such that the wealth to output ratio K F K,N matches the US value of round wto target, digits 3 Auclert and Rognlie, 'Inequality and Aggregate Demand', Appendix B . We can achieve this by minimizing the objective function O \\beta \\left \\frac K \\beta F K \\beta ,N 3.63\\right ^2 where K \\beta denotes the equilibrium capital stock in the Aiyagari model that is associated with a given discount factor \\beta . \" function wealth to output ratio Œ≤, u, firm, statespace, initial bracket hh Œ≤ Household Œ≤ Œ≤, u u r eq find zero r excess demand hh Œ≤, firm, statespace, r , initial bracket, Brent , atol 1e 5, rtol 1e 5, xatol 1e 5, xrtol 1e 5 k eq capital demand firm, r eq return k eq production firm, k eq end wealth to output ratio 0.96, hh2.u, firm, ss2, initial bracket begin Œ≤ vals 0.945 0.005 0.965 wto vals wealth to output ratio Œ≤, hh2.u, firm, ss2, initial bracket for Œ≤ in Œ≤ vals obj vals wto vals . wto target .^ 2 end lines Œ≤ vals, obj vals, axis xlabel L\"discount factor Œ≤ \", ylabel \"value of the objective function\" Œ≤ cal find zero Œ≤ wealth to output ratio Œ≤, hh2.u, firm, ss2, initial bracket wto target, 0.945, 0.965 , Brent , atol 1e 5, rtol 1e 5, xatol 1e 5, xrtol 1e 5 md\"\"\" Appendix \"\"\" TableOfContents md\"\"\" Acknowledgements This notebook has been dramatically improved by Daniel Schmidt https github.com danieljschmidt . \"\"\" "},{"url":"preliminaries/lifecycle/","title":"Lifecycle models","tags":["preliminaries"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 2 section 4 order 4 title \"Lifecycle models\" layout \"layout.jlhtml\" tags \"preliminaries\" description \"\" using Markdown using InteractiveUtils using QuantEcon using Chain, DataFrameMacros, DataFrames using CairoMakie using AlgebraOfGraphics draw using StatsBase using StatsBase weights using AlgebraOfGraphics using AlgebraOfGraphics density using AoGExtensions using LinearAlgebra using LightGraphs using PlutoUI TableOfContents md\"\"\" danger \"Under construction \" This notebook is not ready for public consumption. Use at your own risk. \"\"\" md\"\"\" `lifecycle.jl` | Version 0.1 | last updated Apr 13 2022 \"\"\" md\"\"\" Lifecycle models The setup should be basically identical to the one in `aiyagari.jl`, except that demographic structure is changed. We'll cover the case of finite lifetime and perpetual youth. \"\"\" md\"\"\" Setup \"\"\" function statespace a vals range 1e 10, 20.0, length 200 , z chain states a, z for a ‚àà a vals, z ‚àà z chain.state values | vec states indices a i, z i for a i ‚àà 1 length a vals , z i ‚àà 1 length z chain.state values | vec policies a next for a next ‚àà a vals | vec policies indices a next i for a next i ‚àà 1 length a vals | vec states, states indices, policies, policies indices, z chain end function Household œÉ 1.0, Œ≤ 0.96, m 0.0, u œÉ 1 ? log x x^ 1 œÉ 1 1 œÉ Œ≤, u, m end function setup Q Q, states indices, policies indices, z chain for i next state, next ‚àà enumerate states indices for i policy, a next i ‚àà enumerate policies indices for i state, z i ‚àà enumerate states indices if next.a i a next i Q i state, i policy, i next state z chain.p z i, next.z i end end end end return Q end function setup Q states indices, policies indices, z chain Q zeros length states indices , length policies indices , length states indices setup Q Q, states indices, policies indices, z chain Q end function consumption z, a , a next , q, w, Œîr if a next 0 && Œîr 0 r 1 q 1 a next 0 Œîr q 1 1 r end c w z a q a next c, a next end function reward etc state, policy, prices, u c, a next consumption state, policy, prices if c 0 reward u c else reward 100 000 100 c end reward, c end function setup R etc R, etc, states, policies, prices, u for i policy, policy ‚àà enumerate policies for i state, state ‚àà enumerate states out reward etc state, policy, prices, u R i state, i policy out.reward etc i state, i policy out... end end return nothing end function setup R etc states, policies, prices, u proto reward etc first states , first policies , prices, u T typeof proto etc Array T undef, length states , length policies R zeros length states , length policies setup R etc R, etc, states, policies, prices, u R, etc end md\"\"\" State space \"\"\" r guess hh, scale 0.9 1 hh.Œ≤ 1 hh.m scale q r 1 1 r r from q q 1 q 1 md\"\"\" Solve Households' problem \"\"\" md\"\"\" Infinite lifetime vs finite lifetime vs perpetual youth \"\"\" md\"\"\" Finite lifetime \"\"\" J 40 Create an instance of Household hh Household m 1 J r r guess hh, 0.8 prices q q r , w 1.0, Œîr r 2 function simulate J ddp, J, v term, states, policies , other policies, œÄ‚ÇÄ vs, sigmas backward induction ddp, J, v term initial distribution œÄ copy œÄ‚ÇÄ initialize DataFrame to store the results dfs DataFrame for j ‚àà 1 J œÉ sigmas , j R œÉ, Q œÉ RQ sigma ddp, œÉ op DataFrame other policies i, s for i, s ‚àà enumerate œÉ df DataFrame states DataFrame policies œÉ op df.j . j df.œÄ vec œÄ œÄ œÄ Q œÉ Q initial distribution push dfs, df end vcat dfs... end md\"\"\" Perpetual youth \"\"\" function simulate ddp, J, states, policies , other policies, œÄ‚ÇÄ, solver PFI results QuantEcon.solve ddp, solver œÉ results.sigma R œÉ, Q œÉ RQ sigma ddp, œÉ op DataFrame other policies i, s for i, s ‚àà enumerate œÉ df0 DataFrame states DataFrame policies œÉ op initial distribution œÄ copy œÄ‚ÇÄ initialize DataFrame to store the results dfs DataFrame for j ‚àà 1 J df copy df0 df.j . j df.œÄ vec œÄ œÄ œÄ Q œÉ Q initial distribution push dfs, df end vcat dfs... end md\"\"\" Evolution of assets over age \"\"\" ‚ï†‚ïê‚ï° chain df big begin data mapping j, a, weights œÄ visual Violin draw end ‚ï†‚ïê‚ï° Œµ 0.1 z chain MarkovChain 1 Œµ Œµ Œµ 1 Œµ , 1.25, 0.75 function setup DDP household, statespace, prices Œ≤, m, u household states, policies, states indices, policies indices statespace Rewards and policies R, etc setup R etc states, policies, prices, u Transition function Q setup Q states indices, policies indices, z chain ddp DiscreteDP R, Q, Œ≤ 1 m ddp, R, etc end ss statespace a vals range 2, 2.0, length 200 , z chain Use the instance to build a discrete dynamic program am ddp, etc let ddp, etc setup DDP hh, ss, prices am ddp ddp, etc end v term map ss.states do a, z a ‚â• 0 ? 0 100 000 a end initial distribution let i 0 findfirst DataFrame ss.states .a . 0 œÄ‚ÇÄ map ss.states indices do a i a i i 0 ? 1.0 0.0 end œÄ‚ÇÄ sum œÄ‚ÇÄ end df big simulate J am ddp, J, v term, ss, etc, initial distribution' chain df big begin stack a, a next, c , j, œÄ groupby j, variable combine value mean value, weights œÄ data mapping j, value, layout variable visual ScatterLines draw facet linkyaxes false, end chain df big begin data mapping a, weights œÄ density histogram draw end chain df big begin stack a, a next, c , j, œÄ, z groupby j, variable data mapping j, value, weights œÄ, color z nonnumeric, layout variable quantileband draw facet linkyaxes false, end df big2 simulate am ddp, J, ss, etc, initial distribution' chain df big2 begin stack a, a next, c , j, œÄ groupby j, variable combine value mean value, weights œÄ data mapping j, value, layout variable visual ScatterLines draw facet linkyaxes false, end chain df big2 begin stack a, a next, c , j, œÄ, z groupby j, variable data mapping j, value, weights œÄ, color z nonnumeric, layout variable quantileband draw facet linkyaxes false, end chain df big begin combine a mean a, weights œÄ , a next mean a next, weights œÄ , end chain df big2 begin combine a mean a, weights œÄ , a next mean a next, weights œÄ , end md\"\"\" Perpetual youth \"\"\" md\"\"\" constant death probability ``m`` \"\"\" m 1 45 hh perp youth Household m md\"\"\" Appendix \"\"\" md\"\"\" Stationary distribution \"\"\" begin abstract type StatDistSolver end struct Eigen StatDistSolver end struct GTH StatDistSolver end struct Iterate StatDistSolver end end function stationary distribution mc MarkovChain, solver StatDistSolver GTH kwargs... stationary distribution mc.p, solver kwargs... end function stationary distribution Q AbstractMatrix, m, solver kwargs... QÃÉ 1 m Q m I stationary distribution QÃÉ, solver kwargs... end function stationary distribution Q AbstractMatrix, m, œÄ‚ÇÄ, œÄ m œÄ‚ÇÄ I 1 m Q œÄ' end function stationary distribution Q AbstractMatrix, m, œÄ‚ÇÄ, Iterate maxit 400, œÄ guess œÄ‚ÇÄ, rtol ‚àöeps œÄ copy œÄ guess for i in 1 maxit œÄ new 1 m œÄ Q m œÄ‚ÇÄ if isapprox œÄ new, œÄ rtol info \"Converged after i iterations\" return œÄ new' end if i maxit warn \"Didn't converge after i iterations\" return œÄ new' end œÄ . œÄ new end nothing end function stationary distribution Q AbstractMatrix, GTH this essentially copies the implementation of QuantEcon.jl n size Q, 1 œÄ zeros n ids only attracting components DiGraph Q œÄ ids . gth solve Q ids,ids œÄ end function stationary distribution Q AbstractMatrix, Iterate rtol ‚àöeps , maxit 400 Qn copy Q for i in 1 maxit Qn new Qn Q if isapprox Qn new, Qn rtol info \"Converged after i iterations\" break end if i maxit warn \"Didn't converge after i iterations\" end Qn . Qn new end Qn 1, end function real if real x assert isreal x real x end function stationary distribution Q AbstractMatrix, Eigen values, vectors eigen Q' find unit eigenvalue i only findall values .‚âà 1.0 get corresponding eigenvector œÄ vectors , i make sure it isn't complex, normalize sum to 1 œÄ real if real œÄ œÄ . œÄ sum œÄ end function solve details0 ddp, states, policies , other policies m, œÄ‚ÇÄ, solver PFI results QuantEcon.solve ddp, solver op DataFrame other policies i, s for i, s ‚àà enumerate results.sigma df hcat DataFrame states , DataFrame policies results.sigma , op, makeunique true df.value results.v df.state states df.policy policies results.sigma df.additional policies other policies results.sigma df.œÄ stationary distribution results.mc.p, m, œÄ‚ÇÄ, GTH df, results df end function solve details ddp, statespaces, etc m, œÄ‚ÇÄ, solver PFI df solve details0 ddp, statespaces, etc m, œÄ‚ÇÄ, solver chain df begin select Not state, policy, additional policies end end Solve using policy function iteration results df solve details am ddp, ss, etc hh.m, œÄ‚ÇÄ initial distribution', solver PFI chain results df begin combine a mean a, weights œÄ , a next mean a next, weights œÄ , end chain results df begin groupby a combine œÄ sum œÄ data mapping a, œÄ visual Lines draw end let ddp setup DDP hh perp youth, ss, prices assert ddp.beta hh perp youth.Œ≤ 1 hh perp youth.m m hh perp youth results QuantEcon.solve ddp, PFI œÉ results.sigma R œÉ, Q œÉ RQ sigma ddp, œÉ QÃÉ 1 m Q œÉ m I mc aux MarkovChain copy QÃÉ œÄ only stationary distributions mc aux assert œÄ ‚âà stationary distribution QÃÉ, Eigen assert œÄ ‚âà stationary distribution QÃÉ, GTH assert œÄ ‚âà stationary distribution QÃÉ, Iterate , rtol eps ^ 3 4 assert œÄ ‚âà stationary distribution Q œÉ, m, Eigen assert œÄ ‚âà stationary distribution Q œÉ, m, œÄ', GTH assert œÄ ‚âà stationary distribution Q œÉ, m, œÄ', Iterate œÄ guess fill 1 400, 1, 400 , rtol eps ^ 3 4 end md\"\"\" Misc \"\"\" TableOfContents "},{"url":"preliminaries/rbc-to-imrohoroglu/","title":"RBC & Imrohoroglu (1989) as Markov Chains","tags":["preliminaries"],"text":" A Pluto.jl notebook v0.19.38 frontmatter chapter 2 section 2 order 2 title \"RBC & Imrohoroglu 1989 as Markov Chains\" layout \"layout.jlhtml\" tags \"preliminaries\" description \"\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end using SparseArrays using QuantEcon using Chain, DataFrameMacros using CairoMakie using AlgebraOfGraphics using AlgebraOfGraphics draw using StatsBase using PlutoUI using PlutoUI Slider using DataFrames using LaTeXStrings md\"\"\" `rbc to imrohoroglu.jl` | Version 0.1 | last updated May 2 2023 \"\"\" md\"\"\" Introduction \"\"\" md\"\"\" 1. Recap Finite State Markov Chains \"\"\" ‚ï†‚ïê‚ï° mc MarkovChain 0.5 0.1 0.4 0.1 0.4 0.5 0.3 0.3 0.4 , \"unemployed\", \"employed\", \"other\" ‚ï†‚ïê‚ï° mc tauchen 20, 0.9, 1.0 simulate mc, 10 N length mc.state values I 1000 T 10 sim df mapreduce vcat, 1 I do i DataFrame i, t 1 T, state simulate mc, T end md\"\"\" Tracking individuals \"\"\" chain sim df begin subset i 4 subset i % 50 0 data mapping t L\"time t \", state \"state e.g. income \", color i nonnumeric visual ScatterLines mapping t naive visual VLines draw axis title \"Sample paths of selected agents\", end blue Makie.wong colors 1 md\"\"\" Tracking the whole distribution \"\"\" md\"\"\" ... in a naive way \"\"\" bind t naive Slider 1 10, default 1, show value true chain sim df begin aside begin bins sort unique .state end subset t t naive data mapping state visual Hist bins, color blue, normalization probability draw end let fig Figure chain sim df begin subset t % 10 1 aside begin xtick labels string. sort unique .t xticks collect 1 length xtick labels , xtick labels xlabel L\"time t \" ylabel \"cross sectional distribution\" axis xticks, xlabel, ylabel bins sort unique sim df.state end data mapping state, color t t naive , nonnumeric, offset t nonnumeric visual Hist bins, direction x, normalization probability, scale to 0.6 draw fig 1,1 , axis end fig end md\"\"\" ... in a more sophisticated way assuming a continuum of agents \"\"\" œÄ‚ÇÄ fill 1 N, N initial distribution bind t soph Slider 0 100, default 0, show value true barplot mc.state values, vec œÄ‚ÇÄ' mc.p^ t soph , axis title latexstring \"Cross sectional distribution at \\ t t soph \\ \" let fig Figure ax Axis fig 1,1 , xlabel L\"time t \", ylabel \"cross sectional distribution\" for t ‚àà 0 10 barplot ax, mc.state values, vec œÄ‚ÇÄ' mc.p^t . 4, direction x, offset t, color t t soph ? Makie.wong colors 1 gray40 end fig end md\"\"\" 2. The RBC Model A Sample Path of a Markov Chain \"\"\" md\"\"\" Set up the Dynamic Program \"\"\" z chain MarkovChain 0.75 0.25 0.25 0.75 , 1.25, 0.75 r 0.02 q r 1 1 r prices q q r , w 1.0, Œîr r 2 md\"\"\" Solution is a Markov Chain \"\"\" md\"\"\" 3. Bewley Huggett Aiyagari Tracking the Distribution of a Markov Chain warning \"Note\" We are not solving for the equilibrium interest rate ``r`` here. So we are in Partial Equilibrium setting of Imrohoroglu 1989 . \"\"\" md\"\"\" Specify initial distribution \"\"\" bind t soph ddp Slider 0 100, default 0, show value true md\"\"\" Appendix \"\"\" function Household œÉ 1.0, Œ≤ 0.96, u œÉ 1 ? log x x^ 1 œÉ 1 1 œÉ Œ≤, u end hh Household œÉ 2.0, Œ≤ 0.96 function statespace k vals range 1e 10, 20.0, length 200 , z chain states k, z for k ‚àà k vals, z ‚àà z chain.state values | vec states indices k i, z i for k i ‚àà 1 length k vals , z i ‚àà 1 length z chain.state values | vec policies k next for k next ‚àà k vals | vec policies indices k next i for k next i ‚àà 1 length k vals | vec states, states indices, policies, policies indices, z chain end ss statespace k vals range 1., 5., length 200 , z chain states DataFrame ss.states policies DataFrame ss.policies N ddp length ss.states œÄ‚ÇÄ ddp fill 1 N ddp, N ddp function setup Q Q, states indices, policies indices, z chain for i next state, next ‚àà enumerate states indices for i policy, k next i ‚àà enumerate policies indices for i state, z i ‚àà enumerate states indices if next.k i k next i Q i state, i policy, i next state z chain.p z i, next.z i end end end end return Q end function setup Q states indices, policies indices, z chain Q zeros length states indices , length policies indices , length states indices setup Q Q, states indices, policies indices, z chain Q end function consumption z, k , k next , q, w, Œîr if k next 0 && Œîr 0 r 1 q 1 k next 0 Œîr q 1 1 r end c w z k q k next end function reward state, policy, prices, u c consumption state, policy, prices if c 0 u c else 100 000 100 c end end function setup R R, states, policies, prices, u for k i, policy ‚àà enumerate policies for s i, state ‚àà enumerate states R s i, k i reward state, policy, prices, u end end return R end function setup R states, policies, prices, u R zeros length states , length policies setup R R, states, policies, prices, u end function setup DDP household, statespace, prices Œ≤, u household states, policies, states indices, policies indices statespace R setup R states, policies, prices, u Q setup Q states indices, policies indices, z chain DiscreteDP R, Q, Œ≤ end ddp setup DDP hh, ss, prices results QuantEcon.solve ddp, PFI mc ddp results.mc mc ddp.p | sparse path0 simulate mc ddp, 100 let fig Figure resolution 800, 400 path DataFrame ss.states path0 lines fig 1,1 , path.k, axis title \"evolution of capital\", xlabel \"time\" lines fig 1,2 , path.z, axis title \"evolution of productivity\", xlabel \"time\" fig end barplot mc.state values, vec œÄ‚ÇÄ ddp' mc ddp.p^ t soph ddp , axis title latexstring \"Cross sectional distribution at \\ t t soph ddp \\ \" let fig Figure ax Axis fig 1,1 , xlabel L\"time t \", ylabel \"cross sectional distribution\" for t ‚àà 0 10 barplot ax, mc.state values, vec œÄ‚ÇÄ ddp' mc ddp.p^t . 70, direction x, offset t, color t t soph ddp ? Makie.wong colors 1 gray40 end fig end function solve details0 ddp, states, policies solver PFI results QuantEcon.solve ddp, solver df DataFrame states DataFrame policies results.sigma df.state states df.policy policies results.sigma df.œÄ stationary distributions results.mc , 1 1 df end function solve details ddp, states, policies solver PFI df solve details0 ddp, states, policies solver chain df begin transform consumption consumption state, policy, prices transform saving k next k select Not state, policy end end md\"\"\" Packages \"\"\" TableOfContents "}]